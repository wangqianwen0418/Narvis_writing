\section{Evaluation}
\subsection{Participants}
There are two kinds of participants, editors and audiences,  in our user study.\par 
\textbf{Editors: }they are experts in data visualization. They will be divided into two groups and exploit either Narvis or PowerPoint to generate a slide show that explains a visualization design.  \par
\textbf{Audience: }they have no previous experience in data visualization. A questionnaire is conducted to investigate their knowledge about visualization. They will review the slide show produced by the experts, rank it, give subjective comments, and answer a series of questions to check their understanding of this visualization.\par
For editors, we have 4 postgraduate students, aging between 22-30, and all of them have more than one year experience in data visualization.\par
For audiences, we have 20 under graduate students, whose majors vary from business to biology. According to the questionnaire, none of them have accessed advanced data visualization before. Only 13\% students know the tree map, and none can give a accurate explanation of theme river with topic splitting and merging.  \par
\subsection{Material}
We extract the visualization design and the corresponding literature description from  a visualization design paper by Cui et al\cite{cui_textflow:_2011} \par
We choose this visual design based on two considerations. First, it's not too difficult for a laymen but still a novel design that requires extra effect to clarify its encoding scheme.
Second, it is a typical abstract data visualization that is fully consist of graphical element, not involving 3D image or real world image such like satellite map, which is beyond the coverage of our edge detection algorithm. \par
This visualization design is aimed at providing a better understanding about topic evolution in large text collections. It conveys multiple level results of topic evolution analysis: a set of topics
with splitting/merging relationships among each other, which encodes a series of topic flows, a set of critical events, which encode glyphs, and the keyword correlations, which encode threads.  \par
\subsection{Procedure}
\subsubsection{Producing}
We run a two-hour long sessions, which is consist of 3 phases: (1)\textit{learn visualization}, (2)\textit{idea generation and sketch}, (3)\textit{authoring}.\par
In the \textit{learn visualization} phase, participants read the literature description we extract from the paper, which is two-page long and describes the visual design with diagrams. This phase ends when the participants report the experimenters that they finished reading and understand this visual design. This phase takes about 15min, since all the participants are experts in data visualization and familiar with reading such papers.\par
In the \textit{idea generation and sketch} phase, participants are asked to sketch ideas for introducing \textit{TextFlow} to general public. They are encouraged to give considerations to (1) knowledge base of the audience, (2) information complexity of different visual encodings, (3) attention cues to orientate audience's attention. Participants are asked to think aloud and experimenters are present in the room to observe. \par
In the \textit{authoring} phase, participants implement the ideas in their sketch as many as possible in a one-hour-long session. Participants in control group use Power Point, a presentation making tool that all the participants are familiar with. In experimental group, before authoring, experimenters demonstrate the capacity of Narvis through an automatic step by step tutorial included in Narvis, using intro.js. This training lasts about 15 min and is not counted in the one-hour authoring session. Participants are also allowed to ask additional questions in the authoring phase.\par
\subsubsection{Reviewing and feedback}
We conducted a first pilot study to ensure the clarity of the instructions and control the time of experiments. 

We asked a group of 20 volunteers to evaluate the quality of the generated slide show. We conducted a questionnaire in advance to make sure that they all have no experience or knowledge in advanced data visualization. In a one-hour session, they are asked to view, comment, and rate these slide shows. They also answer a series of questions to check their understanding of the visualization design. \par 
We record video during this session with the participants permission. For participants who review the slide show generated by Narvis, their click activity will be recorded automatically and they can make comments on the slides. These click stream data, as well as the comments stream, will be used to generate a report, which will then send to its editor. \par
To conclude the user study, the experimenters conduct an interview with the participants about their authoring experience, the issues they encountered, if there are any, and the feedback report Narvis generated. \par
\subsection{Results}
We analyzed the following material: 1) video and notes that the experimenters took during the user study session, which the participants consented to. 2) the slides and the sketch created by participants, 3) the interview with the editor participants, 4) the ranking, comments, answers, click stream data from the reviewer participants. While analyzing, we focus on extracting information on the following aspects: 1)
\subsubsection{}
\subsubsection{}
xuke\par
reading 15min\par
draft 5min \par
making slides 40min \par
qiaomu\par
reading 14min\par
draft 5min\par
making slide 40min\par
\subsubsection{Generated slideshow}
\subsubsection{Authoring experience}