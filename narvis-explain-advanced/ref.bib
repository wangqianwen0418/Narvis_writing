
@online{_automated_????,
	title = {Automated Hypothesis Generation Based on Mining Scientific Literature},
	url = {http://delivery.acm.org/10.1145/2630000/2623667/p1877-spangler.pdf?ip=175.159.124.243&id=2623667&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864115377&CFTOKEN=71278738&__acm__=1478936347_b2011b04ad609a52e8ed92eb1e256cad},
	urldate = {2016-11-12},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GEF4HCFQ/p1877-spangler.html:text/html;拍877.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7VK5NCEN/拍877.pdf:application/pdf}
}

@article{dunne_rapid_2012,
	title = {Rapid understanding of scientific paper collections: Integrating statistics, text analytics, and visualization},
	volume = {63},
	issn = {1532-2890},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/asi.22652/abstract},
	doi = {10.1002/asi.22652},
	shorttitle = {Rapid understanding of scientific paper collections},
	abstract = {Keeping up with rapidly growing research fields, especially when there are multiple interdisciplinary sources, requires substantial effort for researchers, program managers, or venture capital investors. Current theories and tools are directed at finding a paper or website, not gaining an understanding of the key papers, authors, controversies, and hypotheses. This report presents an effort to integrate statistics, text analytics, and visualization in a multiple coordinated window environment that supports exploration. Our prototype system, Action Science Explorer ({ASE}), provides an environment for demonstrating principles of coordination and conducting iterative usability tests of them with interested and knowledgeable users. We developed an understanding of the value of reference management, statistics, citation text extraction, natural language summarization for single and multiple documents, filters to interactively select key papers, and network visualization to see citation patterns and identify clusters. A three-phase usability study guided our revisions to {ASE} and led us to improve the testing methods.},
	pages = {2351--2369},
	number = {12},
	journaltitle = {Journal of the American Society for Information Science and Technology},
	shortjournal = {J Am Soc Inf Sci Tec},
	author = {Dunne, Cody and Shneiderman, Ben and Gove, Robert and Klavans, Judith and Dorr, Bonnie},
	urldate = {2016-11-12},
	date = {2012-12-01},
	langid = {english},
	keywords = {graphs, Natural Language Processing, visualization (electronic)},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4HI7GQP2/Dunne 等. - 2012 - Rapid understanding of scientific paper collection.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/ZEC83QP2/abstract.html:text/html}
}

@article{bigelow_iterating_2016,
	title = {Iterating Between Tools to Create and Edit Visualizations},
	volume = {{PP}},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598609},
	abstract = {A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, datadriven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.},
	pages = {1--1},
	number = {99},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bigelow, A. and Drucker, S. and Fisher, D. and Meyer, M.},
	date = {2016},
	keywords = {Bridges, Data visualization, illustration, Image color analysis, iteration, Manuals, Software, Solid modeling, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IKJVRBPV/7539580.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/AS6V4BCB/Bigelow 等. - 2016 - Iterating Between Tools to Create and Edit Visuali.pdf:application/pdf}
}

@article{treisman_feature-integration_1980,
	title = {A feature-integration theory of attention},
	volume = {12},
	issn = {0010-0285},
	url = {http://www.sciencedirect.com/science/article/pii/0010028580900055},
	doi = {10.1016/0010-0285(80)90005-5},
	abstract = {A new hypothesis about the role of focused attention is proposed. The feature-integration theory of attention suggests that attention must be directed serially to each stimulus in a display whenever conjunctions of more than one separable feature are needed to characterize or distinguish the possible objects presented. A number of predictions were tested in a variety of paradigms including visual search, texture segregation, identification and localization, and using both separable dimensions (shape and color) and local elements or parts of figures (lines, curves, etc. in letters) as the features to be integrated into complex wholes. The results were in general consistent with the hypothesis. They offer a new set of criteria for distinguishing separable from integral features and a new rationale for predicting which tasks will show attention limits and which will not.},
	pages = {97--136},
	number = {1},
	journaltitle = {Cognitive Psychology},
	shortjournal = {Cognitive Psychology},
	author = {Treisman, Anne M. and Gelade, Garry},
	urldate = {2017-01-17},
	date = {1980-01},
	file = {ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/NTZUGX9D/0010028580900055.html:text/html}
}

@article{wolfe_guided_1994,
	title = {Guided Search 2.0 A revised model of visual search},
	volume = {1},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/article/10.3758/BF03200774},
	doi = {10.3758/BF03200774},
	abstract = {An important component of routine visual behavior is the ability to find one item in a visual world filled with other, distracting items. This ability to performvisual search has been the subject of a large body of research in the past 15 years. This paper reviews the visual search literature and presents a model of human search behavior. Built upon the work of Neisser, Treisman, Julesz, and others, the model distinguishes between a preattentive, massively parallel stage that processes information about basic visual features (color, motion, various depth cues, etc.) across large portions of the visual field and a subsequent limited-capacity stage that performs other, more complex operations (e.g., face recognition, reading, object identification) over a limited portion of the visual field. The spatial deployment of the limited-capacity process is under attentional control. The heart of the guided search model is the idea that attentional deployment of limited resources isguided by the output of the earlier parallel processes. Guided Search 2.0 ({GS}2) is a revision of the model in which virtually all aspects of the model have been made more explicit and/or revised in light of new data. The paper is organized into four parts: Part 1 presents the model and the details of its computer simulation. Part 2 reviews the visual search literature on preattentive processing of basic features and shows how the {GS}2 simulation reproduces those results. Part 3 reviews the literature on the attentional deployment of limited-capacity processes in conjunction and serial searches and shows how the simulation handles those conditions. Finally, Part 4 deals with shortcomings of the model and unresolved issues.},
	pages = {202--238},
	number = {2},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychonomic Bulletin \& Review},
	author = {Wolfe, Jeremy M.},
	urldate = {2017-01-17},
	date = {1994-06-01},
	langid = {english},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MEH2N525/Wolfe - 1994 - Guided Search 2.0 A revised model of visual search.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FUI6FP2P/BF03200774.html:text/html}
}

@article{borkin_what_2013,
	title = {What Makes a Visualization Memorable?},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.234},
	abstract = {An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.},
	pages = {2306--2315},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Borkin, M. A. and Vo, A. A. and Bylinskii, Z. and Isola, P. and Sunkavalli, S. and Oliva, A. and Pfister, H.},
	date = {2013-12},
	keywords = {Amazon, Artificial Intelligence, Cues, data-ink ratios, data understanding, data visualisation, Data visualization, Encoding, government reports, Humans, Image Interpretation, Computer-Assisted, infographic sources, Information technology, information visualization, Mechanical Turk, memorability, memorability scores, Memory, news media sites, Pattern Recognition, Visual, scientific journals, Task Performance and Analysis, Taxonomy, User-Computer Interface, visual densities, visualization community, Visualization taxonomy, visualization type},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TI8R9V53/6634103.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/V6NHQUXV/Borkin 等. - 2013 - What Makes a Visualization Memorable.pdf:application/pdf}
}

@article{bryan_temporal_2016,
	title = {Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement},
	volume = {{PP}},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598876},
	shorttitle = {Temporal Summary Images},
	abstract = {Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest ({POIs}). We present Temporal Summary Images ({TSIs}) as an approach for both exploring this data and creating stories from it. As a visualization, a {TSI} is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for {TSIs} to conduct two case studies with large-scale, scientific simulation datasets.},
	pages = {1--1},
	number = {99},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bryan, C. and Ma, K. L. and Woodring, J.},
	date = {2016},
	keywords = {Additives, annotations, comic strip visualization, Context, data analysis, Data visualization, Layout, Narrative visualization, storytelling, Strips, time-varying data, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DGNJ8N38/7539294.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6PNWJ4JP/Bryan 等. - 2016 - Temporal Summary Images An Approach to Narrative .pdf:application/pdf}
}

@online{wang_guided_????,
	title = {A Guided Tour of Literature Review: Facilitating Academic Paper Reading with Narrative Visualization},
	url = {http://www.cse.ust.hk/~ywangch/vispaper.pdf},
	author = {wang, yun and Liu, dongyu},
	urldate = {2016-11-06},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PQBUCJCJ/vispaper.html:text/html;vispaper.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/9QX68PD5/vispaper.pdf:application/pdf}
}

@article{lee_more_2015,
	title = {More Than Telling a Story: Transforming Data into Visually Shared Stories},
	volume = {35},
	issn = {0272-1716},
	doi = {10.1109/MCG.2015.99},
	shorttitle = {More Than Telling a Story},
	abstract = {The authors take a closer look at how the visualization community has discussed visual storytelling and present a visual data storytelling process, incorporating steps involved in finding insights (explore data), turning these insights into a narrative (make a story), and communicating this narrative to an audience (tell a story). They also discuss opportunities for future research in visualization as a storytelling medium in the light of this broader process.},
	pages = {84--90},
	number = {5},
	journaltitle = {{IEEE} Computer Graphics and Applications},
	author = {Lee, B. and Riche, N. H. and Isenberg, P. and Carpendale, S.},
	date = {2015-09},
	keywords = {communication, Computer Graphics, Context awareness, data analysis, data transformation, data visualisation, Data visualization, Media, Narratives, Narrative visualization, presentation, Professional communication, Programming, storytelling, storytelling process, visual data story, visual data storytelling process, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GIXPHA4A/7274435.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H8SSG6KN/Lee 等. - 2015 - More Than Telling a Story Transforming Data into .pdf:application/pdf}
}

@article{hullman_visualization_2011,
	title = {Visualization Rhetoric: Framing Effects in Narrative Visualization},
	volume = {17},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2011.255},
	shorttitle = {Visualization Rhetoric},
	abstract = {Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that "tell a story" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation.},
	pages = {2231--2240},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Hullman, J. and Diakopoulos, N.},
	date = {2011-12},
	keywords = {communicative information visualization, connotation., critical theory, data visualisation, Data visualization, decision making, denotation, design tactics, end-user interpretation, exploratory information visualization, framing effects, journalism, literary study, narrative information visualization, Narrative visualization, political messaging, political theory, Rhetoric, semiotics, textual annotation, visualization rhetoric, visual representation, wait for reading},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/UVQ23A94/6064988.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2SJ6CART/Hullman 和 Diakopoulos - 2011 - Visualization Rhetoric Framing Effects in Narrati.pdf:application/pdf}
}

@article{borkin_beyond_2016,
	title = {Beyond Memorability: Visualization Recognition and Recall},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467732},
	shorttitle = {Beyond Memorability},
	abstract = {In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable “at-a-glance” are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.},
	pages = {519--528},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Borkin, M. A. and Bylinskii, Z. and Kim, N. W. and Bainbridge, C. M. and Yeh, C. S. and Borkin, D. and Pfister, H. and Oliva, A.},
	date = {2016-01},
	keywords = {0, Atmospheric measurements, data visualisation, Data visualization, Encoding, eye-tracking study, information visualization, memorability, participant-generated text description, Particle measurements, qualitative design guidelines, recall, recognition, Redundancy, Target recognition, Visualization, visualization message, visualization recall, visualization recognition},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MICWQURA/7192646.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/UR6BRDHB/Borkin 等. - 2016 - Beyond Memorability Visualization Recognition and.pdf:application/pdf}
}

@article{brehmer_timelines_2016,
	title = {Timelines Revisited: A Design Space and Considerations for Expressive Storytelling},
	volume = {{PP}},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2614803},
	shorttitle = {Timelines Revisited},
	abstract = {There are many ways to visualize event sequences as timelines. In a storytelling context where the intent is to convey multiple narrative points, a richer set of timeline designs may be more appropriate than the narrow range that has been used for exploratory data analysis by the research community. Informed by a survey of 263 timelines, we present a design space for storytelling with timelines that balances expressiveness and effectiveness, identifying 14 design choices characterized by three dimensions: representation, scale, and layout. Twenty combinations of these choices are viable timeline designs that can be matched to different narrative points, while smooth animated transitions between narrative points allow for the presentation of a cohesive story, an important aspect of both interactive storytelling and data videos. We further validate this design space by realizing the full set of viable timeline designs and transitions in a proof-of-concept sandbox implementation that we used to produce seven example timeline stories. Ultimately, this work is intended to inform and inspire the design of future tools for storytelling with timelines.},
	pages = {1--1},
	number = {99},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Brehmer, M. and Lee, B. and Bach, B. and Riche, N. Henry and Munzner, T.},
	date = {2016},
	keywords = {animated transitions, Biographies, Context, Data visualization, design space, history, Layout, Narrative visualization, storytelling, Timelines, Videos, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QAP8UZNA/7581076.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H54R88FG/Brehmer 等. - 2016 - Timelines Revisited A Design Space and Considerat.pdf:application/pdf}
}

@online{_summarizing_????,
	title = {Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status},
	url = {http://www.mitpressjournals.org/doi/pdf/10.1162/089120102762671936},
	urldate = {2016-11-19},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2VWG3JQK/089120102762671936.html:text/html;089120102762671936.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/9TV57P7V/089120102762671936.pdf:application/pdf}
}

@inproceedings{kuhn_codetimeline:_2012,
	title = {{CodeTimeline}: Storytelling with versioning data},
	doi = {10.1109/ICSE.2012.6227086},
	shorttitle = {{CodeTimeline}},
	abstract = {Working with a software system typically requires knowledge of the system's history, however this knowledge is often only tribal memory of the development team. In past user studies we have observed that when being presented with collaboration views and word clouds from the system's history engineers start sharing memories linked to those visualizations. In this paper we propose an approach based on a storytelling visualization, which is designed to entice engineers to share and document their tribal memory. Sticky notes can be used to share memories of a system's lifetime events, such as past design rationales but also more casual memories like pictures from after-work beer or a hackathon. We present an early-stage prototype implementation and include two design studies created using that prototype.},
	eventtitle = {2012 34th International Conference on Software Engineering ({ICSE})},
	pages = {1333--1336},
	booktitle = {2012 34th International Conference on Software Engineering ({ICSE})},
	author = {Kuhn, A. and Stocker, M.},
	date = {2012-06},
	keywords = {codetimeline, Collaboration, collaboration views, data visualisation, Data visualization, early-stage prototype implementation, history, humanities, Humans and Social Aspects, program visualisation, Prototypes, Software, Software Evolution, software system, Software Visualization, Sticky notes, storytelling visualization, Tag clouds, Tools and Environments, tribal memory, versioning data, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BDK6IJTP/6227086.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CTUXDN8F/Kuhn 和 Stocker - 2012 - CodeTimeline Storytelling with versioning data.pdf:application/pdf}
}

@article{kosara_storytelling:_2013,
	title = {Storytelling: The Next Step for Visualization},
	volume = {46},
	issn = {0018-9162},
	doi = {10.1109/MC.2013.36},
	shorttitle = {Storytelling},
	abstract = {Presentation-specifically, its use of elements from storytelling-is the next logical step in visualization research and should be a focus of at least equal importance with exploration and analysis.},
	pages = {44--50},
	number = {5},
	journaltitle = {Computer},
	author = {Kosara, R. and Mackinlay, J.},
	date = {2013-05},
	keywords = {Collaboration, data visualisation, Data visualization, Narratives, presentation, storytelling, visual communication, Visual databases, Visual effects, Visualization, visualization research},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/ZPJJSXJQ/6412677.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/K649TBJV/Kosara 和 Mackinlay - 2013 - Storytelling The Next Step for Visualization.pdf:application/pdf}
}

@online{_storytelling_????,
	title = {Storytelling in Visual Analytics Tools for Business Intelligence},
	url = {http://download.springer.com/static/pdf/473/chp%253A10.1007%252F978-3-642-40477-1_18.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-642-40477-1_18&token2=exp=1479549295~acl=%2Fstatic%2Fpdf%2F473%2Fchp%25253A10.1007%25252F978-3-642-40477-1_18.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F978-3-642-40477-1_18*~hmac=16d5278a3c7dcf91b1600716d24a373c4ebf46d33a265f0a856e61526051b899},
	urldate = {2016-11-19},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7KVSKRIB/chp%3A10.1007%2F978-3-642-40477-1_18.html:text/html;chp%3A10.1007%2F978-3-642-40477-1_18.html:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QKU6AF9G/chp%3A10.1007%2F978-3-642-40477-1_18.html:text/html;chp%253A10.1007%252F978-3-642-40477-1_18.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IP56VEKA/chp%253A10.1007%252F978-3-642-40477-1_18.pdf:application/pdf}
}

@online{_automated_????-1,
	title = {Automated Interactive Narrative Synthesis using Dramatic Theory},
	url = {http://delivery.acm.org/10.1145/2830000/2822028/p103-dominguez.pdf?ip=175.159.124.243&id=2822028&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1480045870_f953283e45512d29948f9fcff8e0f18f},
	urldate = {2016-11-25},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/XH5J2A4G/p103-dominguez.html:text/html;p103-dominguez.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H5H6BB7Z/p103-dominguez.pdf:application/pdf}
}

@online{_digestmanga:_????,
	title = {{DigestManga}: Interactive Movie Summarizing through Comic Visualization},
	url = {http://delivery.acm.org/10.1145/1760000/1754050/p3751-tobita.pdf?ip=175.159.124.243&id=1754050&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1480252920_606328c3fd7fb1931880a3373ba1a337},
	urldate = {2016-11-27},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/NZB462GU/p3751-tobita.html:text/html;p3751-tobita.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2KUZC3W6/p3751-tobita.pdf:application/pdf}
}

@online{_interactive_????,
	title = {Interactive Multimedia Summaries of Evaluative Text},
	url = {http://delivery.acm.org/10.1145/1120000/1111480/p124-carenini.pdf?ip=175.159.124.243&id=1111480&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1480253074_b1d8e5f4b21ee7cdbfb208276d4b8dd4},
	urldate = {2016-11-27},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/W5FG6B2I/p124-carenini.html:text/html;p124-carenini.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RSQ8298P/p124-carenini.pdf:application/pdf}
}

@inproceedings{dou_leadline:_2012,
	title = {{LeadLine}: Interactive visual analysis of text data through event identification and exploration},
	doi = {10.1109/VAST.2012.6400485},
	shorttitle = {{LeadLine}},
	abstract = {Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, {LeadLine}, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, {LeadLine} integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, {LeadLine} allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, {LeadLine} provides a concise summary of the corpora. {LeadLine} also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of {LeadLine} in identifying events and supporting exploration, two case studies were conducted using news and social media data.},
	eventtitle = {2012 {IEEE} Conference on Visual Analytics Science and Technology ({VAST})},
	pages = {93--102},
	booktitle = {2012 {IEEE} Conference on Visual Analytics Science and Technology ({VAST})},
	author = {Dou, W. and Wang, X. and Skau, D. and Ribarsky, W. and Zhou, M. X.},
	date = {2012-10},
	keywords = {automatically identify meaningful events, Crawlers, data mining, entity recognition techniques, Event detection, event exploration, event identification, information extraction, information retrieval, interactive visual analysis, interactive visual analytics system, large-scale text corpora, Lead, {LeadLine}, microblogs, news data, online news, social media data, social networking (online), support exploration, text analysis, text data, Time series analysis, Twitter, Visualization, visual text analysis systems},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/Z9FC6EUR/6400485.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DAHCXEJ9/Dou 等. - 2012 - LeadLine Interactive visual analysis of text data.pdf:application/pdf}
}

@article{isenberg_visualization_2017,
	title = {Visualization as Seen through its Research Paper Keywords},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598827},
	abstract = {We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the {IEEE} Visualization conference series (now called {IEEE} {VIS}) between 1990–2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the {IEEE} {VIS} reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for {IEEE} {VIS} papers since 1990 to find related work or make informed keyword choices.},
	pages = {771--780},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Isenberg, P. and Isenberg, T. and Sedlmair, M. and Chen, J. and M?ller, T.},
	date = {2017-01},
	keywords = {data analysis, data mining, Data models, Data visualization, Market research, research themes, research topics, Taxonomy, theory, Visualization, visualization history, vocabulary},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/KAJWX9UG/7539364.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/KKPVZ27X/Isenberg 等. - 2017 - Visualization as Seen through its Research Paper K.pdf:application/pdf}
}

@article{amini_authoring_2017,
	title = {Authoring Data-Driven Videos with {DataClips}},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598647},
	abstract = {Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce {DataClips}, an authoring tool aimed at lowering the barriers to crafting data videos. {DataClips} allows non-experts to assemble data-driven “clips” together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that {DataClips} can reproduce over 90\% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using {DataClips}, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use {DataClips} with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.},
	pages = {501--510},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Amini, F. and Riche, N. H. and Lee, B. and Monroy-Hernandez, A. and Irani, P.},
	date = {2017-01},
	keywords = {Animation, authoring tools, data storytelling, data video, Data visualization, Libraries, Media, Narrative visualization, Videos, Visualization, visualization systems},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PF6QKW6E/7539370.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/N54XWJXI/Amini 等. - 2017 - Authoring Data-Driven Videos with DataClips.pdf:application/pdf}
}

@online{_emerging_????,
	title = {Emerging and Recurring Data-Driven Storytelling Techniques: Analysis of a Curated Collection of Recent Stories},
	url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/MSR-TR-2016-14-Storytelling-Techniques-1.pdf},
	urldate = {2017-01-08},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/NTM8CJ8M/MSR-TR-2016-14-Storytelling-Techniques-1.html:text/html;MSR-TR-2016-14-Storytelling-Techniques-1.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U364SNPQ/MSR-TR-2016-14-Storytelling-Techniques-1.pdf:application/pdf}
}

@article{hullman_deeper_2013,
	title = {A Deeper Understanding of Sequence in Narrative Visualization},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.119},
	abstract = {Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.},
	pages = {2406--2415},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Hullman, J. and Drucker, S. and Riche, N. Henry and Lee, B. and Fisher, D. and Adar, E.},
	date = {2013-12},
	keywords = {Algorithms, Artificial Intelligence, audience perspective, automatic effective sequence identification, cognition, Comprehension, Computer Graphics, data storytelling, data visualisation, Data visualization, Encoding, global sequencing strategies, graph-driven approach, graph theory, humanities, Humans, Linear programming, local transitions, Multimodal Imaging, Narration, narrative sequencing, narrative structure, narrative systems, Narrative visualization, Parallel processing, Pattern Recognition, Visual, professional narrative visualizations, qualitative analysis, Reproducibility of Results, Sensitivity and Specificity, sequences, Sequential analysis, slideshow-style presentations, User-Computer Interface, user preferences, visualization sequence optimization, visualization set, visualization-to-visualization transitions, Visual Perception},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/E7ESNZEM/6634182.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U5XJD88A/Hullman 等. - 2013 - A Deeper Understanding of Sequence in Narrative Vi.pdf:application/pdf}
}

@article{bach_graphdiaries:_2014,
	title = {{GraphDiaries}: Animated Transitions {andTemporal} Navigation for Dynamic Networks},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.254},
	shorttitle = {{GraphDiaries}},
	abstract = {Identifying, tracking and understanding changes in dynamic networks are complex and cognitively demanding tasks. We present {GraphDiaries}, a visual interface designed to improve support for these tasks in any node-link based graph visualization system. {GraphDiaries} relies on animated transitions that highlight changes in the network between time steps, thus helping users identify and understand those changes. To better understand the tasks related to the exploration of dynamic networks, we first introduce a task taxonomy, that informs the design of {GraphDiaries}, presented afterwards. We then report on a user study, based on representative tasks identified through the taxonomy, and that compares {GraphDiaries} to existing techniques for temporal navigation in dynamic networks, showing that it outperforms them in terms of both task time and errors for several of these tasks.},
	pages = {740--754},
	number = {5},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bach, B. and Pietriga, E. and Fekete, J. D.},
	date = {2014-05},
	keywords = {animated transitions, Animation, Complexity theory, computer animation, data visualisation, dynamic networks, {GraphDiaries}, graphical user interfaces, graph theory, Graph Visualization, Layout, Navigation, network theory (graphs), node-link-based graph visualization system, task errors, task taxonomy, task time, Taxonomy, temporal navigation, time steps, Topology, user experiment, visual interface, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/R7QJX9T6/6658746.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6DBB7TUH/Bach 等. - 2014 - GraphDiaries Animated Transitions andTemporal Nav.pdf:application/pdf}
}

@inproceedings{eccles_stories_2007,
	title = {Stories in {GeoTime}},
	doi = {10.1109/VAST.2007.4388992},
	abstract = {A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in {GeoTime}. The {GeoTime} geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.},
	eventtitle = {2007 {IEEE} Symposium on Visual Analytics Science and Technology},
	pages = {19--26},
	booktitle = {2007 {IEEE} Symposium on Visual Analytics Science and Technology},
	author = {Eccles, R. and Kapler, T. and Harper, R. and Wright, W.},
	date = {2007-10},
	keywords = {analytic sense-making cohesion, Collaboration, Context, data mining, data visualisation, Data visualization, Event detection, geographic information systems, {GeoTime} geo-temporal event visualization tool, graphical user interfaces, human information interaction, humanities, Humans, hypertext linked visualization, Information analysis, narrative, Pattern analysis, pattern detection, sense-making, story making, story system, story telling, Visual analytics, visual annotation},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/8CKP5RCR/4388992.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/C54CQI3S/Eccles 等. - 2007 - Stories in GeoTime.pdf:application/pdf}
}

@online{_mylifebits:_????,
	title = {{MyLifeBits}: A Personal Database for Everything},
	url = {http://delivery.acm.org/10.1145/1110000/1107460/p88-gemmell.pdf?ip=175.159.124.243&id=1107460&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1483929851_94ae270093b0559ad7632e73037354ce},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IJDMNVI2/p88-gemmell.html:text/html}
}

@online{_lifelines:_????,
	title = {{LifeLines}: Visualizing Personal Histories},
	url = {http://delivery.acm.org/10.1145/240000/238493/p221-plaisant.pdf?ip=175.159.124.243&id=238493&acc=ACTIVE%20SERVICE&key=CDD1E79C27AC4E65%2EFC30B8D6EF32B758%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=864383968&CFTOKEN=25890672&__acm__=1483930263_e1115093b24d2dc28be2c214291f5e81},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/R3X7DJCE/p221-plaisant.html:text/html;p221-plaisant.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MVZEM8F4/p221-plaisant.pdf:application/pdf}
}

@online{_automatic_????,
	title = {Automatic generation of visual story for fairy tales with digital narrative},
	url = {http://content.iospress.com/download/web-intelligence/web314?id=web-intelligence%2Fweb314},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TMV6A5RV/web314.html:text/html}
}

@online{_meseum:_????,
	title = {{MEseum}: Personalized Experience with Narrative Visualization for Museum Visitors},
	url = {http://download.springer.com/static/pdf/906/chp%253A10.1007%252F978-3-319-39513-5_17.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-319-39513-5_17&token2=exp=1483947550~acl=%2Fstatic%2Fpdf%2F906%2Fchp%25253A10.1007%25252F978-3-319-39513-5_17.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F978-3-319-39513-5_17*~hmac=3acaaccc59aedc862b49311e75258fd6eabfe5bee290404dda7c1f4fc6628c05},
	urldate = {2017-01-09},
	file = {:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GTVFDRUZ/chp%3A10.1007%2F978-3-319-39513-5_17.html:text/html}
}

@inproceedings{kucher_text_2015,
	title = {Text visualization techniques: Taxonomy, visual survey, and community insights},
	doi = {10.1109/PACIFICVIS.2015.7156366},
	shorttitle = {Text visualization techniques},
	abstract = {Text visualization has become a growing and increasingly important subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this paper, we present an interactive visual survey of text visualization techniques that can be used for the purposes of search for related work, introduction to the subfield and gaining insight into research trends. We describe the taxonomy used for categorization of text visualization techniques and compare it to approaches employed in several other surveys. Finally, we present results of analyses performed on the entries data.},
	eventtitle = {2015 {IEEE} Pacific Visualization Symposium ({PacificVis})},
	pages = {117--121},
	booktitle = {2015 {IEEE} Pacific Visualization Symposium ({PacificVis})},
	author = {Kucher, K. and Kerren, A.},
	date = {2015-04},
	keywords = {Browsers, categorization taxonomy, community analysis, community insight, data analysis, data visualisation, Data visualization, Interaction, interactive systems, interactive visual survey, Market research, Media, pattern classification, survey, Taxonomy, text analysis, Text visualization, text visualization technique, Visualization, web-based systems},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/73RJG4JZ/7156366.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/34CFJQBB/Kucher 和 Kerren - 2015 - Text visualization techniques Taxonomy, visual su.pdf:application/pdf}
}

@article{he_vizitcards:_2017,
	title = {{VizItCards}: A Card-Based Toolkit for Infovis Design Education},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2599338},
	shorttitle = {{VizItCards}},
	abstract = {Shifts in information visualization practice are forcing a reconsideration of how infovis is taught. Traditional curricula that focused on conveying research-derived knowledge are slowly integrating design thinking as a key learning objective. In part, this is motivated by the realization that infovis is a wicked design problem, requiring a different kind of design work. In this paper we describe, {VizItCards}, a card-driven workshop developed for our graduate infovis class. The workshop is intended to provide practice with good design techniques and to simultaneously reinforce key concepts. {VizItCards} relies on principles of collaborative-learning and research on parallel design to generate positive collaborations and high-quality designs. From our experience of simulating a realistic design scenario in a classroom setting, we find that our students were able to meet key learning objectives and their design performance improved during the class. We describe variants of the workshop, discussing which techniques we think match to which learning goals.},
	pages = {561--570},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {He, S. and Adar, E.},
	date = {2017-01},
	keywords = {card, card-based toolkit, card-driven workshop, Collaboration, collaborative-learning, computer aided instruction, Conferences, data visualisation, Data visualization, design workshop, Education, Human computer interaction, information visualization education, infovis design education, parallel design, peer learning, Standards, toolkit, Visualization, {VizItCards}},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/3HFFE77E/7539629.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/ZQK7V9AJ/He 和 Adar - 2017 - VizItCards A Card-Based Toolkit for Infovis Desig.pdf:application/pdf}
}

@article{robertson_effectiveness_2008,
	title = {Effectiveness of Animation in Trend Visualization},
	volume = {14},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.125},
	abstract = {Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.},
	pages = {1325--1332},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Robertson, G. and Fernandez, R. and Fisher, D. and Lee, B. and Stasko, J.},
	date = {2008-11},
	keywords = {Animation, computer animation, data analysis, data visualisation, Data visualization, design, Dictionaries, Displays, experiment, Gapminder Trendalyzer, Index Terms—Information visualization, trend animation, trends, trend visualization, wait for reading},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GSP7B7E3/4658146.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/48QAZVMR/Robertson 等. - 2008 - Effectiveness of Animation in Trend Visualization.pdf:application/pdf}
}

@article{waldner_attractive_2014,
	title = {Attractive Flicker \#x2014; Guiding Attention in Dynamic Narrative Visualizations},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346352},
	abstract = {Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first “orientation stage” is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (“engagement stage”) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.},
	pages = {2456--2465},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Waldner, M. and Muzic, M. Le and Bernhard, M. and Purgathofer, W. and Viola, I.},
	date = {2014-12},
	keywords = {attention attraction, attention guidance, attraction effectiveness, Attractive Flicker technique, brightness, Context awareness, context suppression, Data models, data visualisation, Data visualization, dynamic narrative visualizations, engagement stage, flicker, focus elements, focus-plus-context techniques, human factors, Image color analysis, large-dynamic scene, minimally-disturbing luminance oscillation, minimal visual deformation, molecular interactions, Narrative visualization, Observers, orientation stage, perceptual statistics, perceptual studies, short-intensive flicker stimulus, signal parameters, signal stages, Social network services, subjective annoyance, subjective disturbance, visual attention, visual attractor, visual feature, visual field, visual guidance, Visual Perception, visual prominence, visual support, wait for reading},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PWWPFMH8/6876019.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/HTXIV8XC/Waldner 等. - 2014 - Attractive Flicker #x2014\; Guiding Attention in Dy.pdf:application/pdf}
}

@article{segel_narrative_2010,
	title = {Narrative Visualization: Telling Stories with Data},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.179},
	shorttitle = {Narrative Visualization},
	abstract = {Data visualization is regularly promoted for its ability to reveal stories within data, yet these “data stories” differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.},
	pages = {1139--1148},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Segel, E. and Heer, J.},
	date = {2010-11},
	keywords = {case study, data story, data visualisation, Data visualization, design differences, design methods, Economics, educational aids, educational media, Engineering profession, humanities, Image color analysis, journalism, journalistic storytelling, Media, Narrative visualization, online journalists, social data analysis, storytelling, telling story, Visualization, visualization research},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U27TTCX3/5613452.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/39W6GJEG/Segel 和 Heer - 2010 - Narrative Visualization Telling Stories with Data.pdf:application/pdf}
}

@article{satyanarayan_authoring_2014,
	title = {Authoring Narrative Visualizations with Ellipsis},
	volume = {33},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cgf.12392/abstract},
	doi = {10.1111/cgf.12392},
	abstract = {Data visualization is now a popular medium for journalistic storytelling. However, current visualization tools either lack support for storytelling or require significant technical expertise. Informed by interviews with journalists, we introduce a model of storytelling abstractions that includes state-based scene structure, dynamic annotations and decoupled coordination of multiple visualization components. We instantiate our model in Ellipsis: a system that combines a domain-specific language ({DSL}) for storytelling with a graphical interface for story authoring. User interactions are automatically translated into statements in the Ellipsis {DSL}. By enabling storytelling without programming, the Ellipsis interface lowers the threshold for authoring narrative visualizations. We evaluate Ellipsis through example applications and user studies with award-winning journalists. Study participants find Ellipsis to be a valuable prototyping tool that can empower journalists in the creation of interactive narratives.},
	pages = {361--370},
	number = {3},
	journaltitle = {Computer Graphics Forum},
	shortjournal = {Computer Graphics Forum},
	author = {Satyanarayan, Arvind and Heer, Jeffrey},
	urldate = {2017-01-22},
	date = {2014-06-01},
	langid = {english},
	keywords = {Categories and Subject Descriptors (according to {ACM} {CCS}):, H.5.2 [Information Interfaces]: User Interfaces—{GUI}},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7IU5GSSM/Satyanarayan 和 Heer - 2014 - Authoring Narrative Visualizations with Ellipsis.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/W4GUFF28/abstract.html:text/html}
}

@inproceedings{huber_visualizing_2005,
	title = {Visualizing data with motion},
	doi = {10.1109/VISUAL.2005.1532838},
	abstract = {This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20°, and velocity must differ by at least 0.43° of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, and then discuss future work we plan to pursue.},
	eventtitle = {{VIS} 05. {IEEE} Visualization, 2005.},
	pages = {527--534},
	booktitle = {{VIS} 05. {IEEE} Visualization, 2005.},
	author = {Huber, D. E. and Healey, C. G.},
	date = {2005-10},
	keywords = {Computer Graphics, data visualisation, Data visualization, direction property, flicker property, Guidelines, Humans, Image analysis, Image converters, image motion analysis, Information analysis, motion perceptual property, Multidimensional systems, Performance analysis, velocity property, Visual system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U656WWGJ/1532838.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BAQQQBV2/Huber 和 Healey - 2005 - Visualizing data with motion.pdf:application/pdf}
}

@book{munzner_visualization_2014,
	title = {Visualization Analysis and Design},
	isbn = {978-1-4665-0893-4},
	abstract = {Learn How to Design Effective Visualization Systems Visualization Analysis and Design provides a systematic, comprehensive framework for thinking about visualization in terms of principles and design choices. The book features a unified approach encompassing information visualization techniques for abstract data, scientific visualization techniques for spatial data, and visual analytics techniques for interweaving data transformation and analysis with interactive visual exploration. It emphasizes the careful validation of effectiveness and the consideration of function before form.   The book breaks down visualization design according to three questions: what data users need to see, why users need to carry out their tasks, and how the visual representations proposed can be constructed and manipulated. It walks readers through the use of space and color to visually encode data in a view, the trade-offs between changing a single view and using multiple linked views, and the ways to reduce the amount of data shown in each view. The book concludes with six case studies analyzed in detail with the full framework.  The book is suitable for a broad set of readers, from beginners to more experienced visualization designers. It does not assume any previous experience in programming, mathematics, human–computer interaction, or graphic design and can be used in an introductory visualization course at the graduate or undergraduate level.},
	pagetotal = {422},
	publisher = {{CRC} Press},
	author = {Munzner, Tamara},
	date = {2014-12-01},
	langid = {english},
	note = {Google-Books-{ID}: {dznSBQAAQBAJ}},
	keywords = {Business \& Economics / Statistics, Computers / Computer Graphics, Computers / Databases / General, Computers / General, Computers / Social Aspects / Human-Computer Interaction, Technology \& Engineering / Industrial Health \& Safety}
}

@article{heer_animated_2007,
	title = {Animated Transitions in Statistical Data Graphics},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70539},
	abstract = {In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in {DynaVis}, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.},
	pages = {1240--1247},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Heer, J. and Robertson, G.},
	date = {2007-11},
	keywords = {animated transitions, Animation, bar charts, Collaboration, computer animation, data visualisation, Data visualization, design, Drilling, {DynaVis}, experiment, graphical perception, Graphics, Guidelines, Information analysis, information visualization, Marketing and sales, pie charts, Scattering, scatter plots, statistical analysis, statistical data graphics, Taxonomy, transitions, visualization system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TID3N57S/4376146.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/XA2X2EUJ/Heer 和 Robertson - 2007 - Animated Transitions in Statistical Data Graphics.pdf:application/pdf}
}

@inproceedings{figueiras_narrative_2014,
	title = {Narrative Visualization: A Case Study of How to Incorporate Narrative Elements in Existing Visualizations},
	doi = {10.1109/IV.2014.79},
	shorttitle = {Narrative Visualization},
	abstract = {Stories have long been used to convey information, cultural values, and experiences. Narratives not only have been the main way people make sense of the world, but also have been the easiest way humans found out to share complex information. However, today we are confronted with the problem of the amount of information available, which sometimes is hard to cope with. Combining storytelling with visualization has been pointed out as an efficient method to represent and make sense of data, at the same time allowing people to relate with the information. In this paper, we explore the benefits of adding storytelling to visualizations. Drawing on case studies from news media to visualization research websites, we identified possible strategies to introduce storytelling in visualizations such as adding short stories or narrative elements using annotations and using time to introduce the feeling of storytelling or story-flow.},
	eventtitle = {2014 18th International Conference on Information Visualisation},
	pages = {46--52},
	booktitle = {2014 18th International Conference on Information Visualisation},
	author = {Figueiras, A.},
	date = {2014-07},
	keywords = {case study, complex information, Complexity theory, Context, data visualisation, Data visualization, history, humanities, Media, narrative elements, Narrative visualization, news media, Rhetoric, story-flow, storytelling, Visualization, visualization research Web sites, Web sites},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/75MBWM3A/6902879.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/F5TAAV5B/Figueiras - 2014 - Narrative Visualization A Case Study of How to In.pdf:application/pdf}
}

@article{cohn_visual_2013,
	title = {Visual Narrative Structure},
	volume = {37},
	issn = {1551-6709},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cogs.12016/abstract},
	doi = {10.1111/cogs.12016},
	abstract = {Narratives are an integral part of human expression. In the graphic form, they range from cave paintings to Egyptian hieroglyphics, from the Bayeux Tapestry to modern day comic books (Kunzle, 1973; {McCloud}, 1993). Yet not much research has addressed the structure and comprehension of narrative images, for example, how do people create meaning out of sequential images? This piece helps fill the gap by presenting a theory of Narrative Grammar. We describe the basic narrative categories and their relationship to a canonical narrative arc, followed by a discussion of complex structures that extend beyond the canonical schema. This demands that the canonical arc be reconsidered as a generative schema whereby any narrative category can be expanded into a node in a tree structure. Narrative “pacing” is interpreted as a reflection of various patterns of this embedding: conjunction, left-branching trees, center-embedded constituencies, and others. Following this, diagnostic methods are proposed for testing narrative categories and constituency. Finally, we outline the applicability of this theory beyond sequential images, such as to film and verbal discourse, and compare this theory with previous approaches to narrative and discourse.},
	pages = {413--452},
	number = {3},
	journaltitle = {Cognitive Science},
	author = {Cohn, Neil},
	urldate = {2017-01-22},
	date = {2013-04-01},
	langid = {english},
	keywords = {Comics, Discourse, Film, narrative, Visual language},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/AG2ZA3IB/Cohn - 2013 - Visual Narrative Structure.pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4G27ME96/abstract.html:text/html}
}

@article{gershon_what_2001,
	title = {What Storytelling Can Do for Information Visualization},
	volume = {44},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/381641.381653},
	doi = {10.1145/381641.381653},
	pages = {31--37},
	number = {8},
	journaltitle = {Commun. {ACM}},
	author = {Gershon, Nahum and Page, Ward},
	urldate = {2017-01-23},
	date = {2001-08},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/U4UN98DF/Gershon 和 Page - 2001 - What Storytelling Can Do for Information Visualiza.pdf:application/pdf}
}

@online{_practical_????,
	title = {A Practical Iterative Framework for Qualitative Data Analysis},
	url = {http://journals.sagepub.com/doi/pdf/10.1177/160940690900800107},
	urldate = {2017-01-23},
	file = {160940690900800107.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/B5GXSKAX/160940690900800107.pdf:application/pdf}
}

@article{mackinlay_show_2007,
	title = {Show Me: Automatic Presentation for Visual Analysis},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70594},
	shorttitle = {Show Me},
	abstract = {This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is {VizQL}, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.},
	pages = {1137--1144},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Mackinlay, J. and Hanrahan, P. and Stolte, C.},
	date = {2007-11},
	keywords = {algebraic specification, algebraic specification language, automatic presentation, Best practices, Computer Graphics, data analysis, data visualisation, Data visualization, Displays, Encoding, Expert Systems, graphic design, Graphics, Information analysis, Information Storage and Retrieval, Programming Languages, small multiple display, small multiples., Software, Software Design, specification languages, User-Computer Interface, user interface, user interfaces, visual analysis, visual analysis system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IC5VQG6D/4376133.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4AJM5853/Mackinlay 等. - 2007 - Show Me Automatic Presentation for Visual Analysi.pdf:application/pdf}
}

@online{schmidt_living_2017,
	title = {the living handbook of narratology},
	author = {Schmidt, Johann N.},
	date = {2017-01-23},
	file = {Narration in Film - the living handbook of narratology:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/V5BDPHIN/index.html:text/html}
}

@inproceedings{amini_understanding_2015,
	location = {New York, {NY}, {USA}},
	title = {Understanding Data Videos: Looking at Narrative Visualization Through the Cinematography Lens},
	isbn = {978-1-4503-3145-6},
	url = {http://doi.acm.org/10.1145/2702123.2702431},
	doi = {10.1145/2702123.2702431},
	series = {{CHI} '15},
	shorttitle = {Understanding Data Videos},
	abstract = {Data videos, motion graphics that incorporate visualizations about facts, are increasingly gaining popularity as a means of telling stories with data. However, very little is systematically recorded about (a) what elements are featured in data videos and (b) the processes used to create them. In this article, we provide initial insights to build this knowledge. We first report on a qualitative analysis of 50 professionally designed data videos, extracting and exposing their most salient constituents. Second, we report on a series of workshops with experienced storytellers from cinematography, graphics design and screenplay writing. We provided them with a set of data facts and visualizations and observed them create storyboards for data videos. From these exploratory studies, we derive broader implications for the design of an authoring tool to enable a wide audience to create data videos. Our findings highlight the importance of providing a flexible tool supporting a non-linear creation process and allowing users to iteratively go back to different phases of the process.},
	pages = {1459--1468},
	booktitle = {Proceedings of the 33rd Annual {ACM} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Amini, Fereshteh and Henry Riche, Nathalie and Lee, Bongshin and Hurter, Christophe and Irani, Pourang},
	urldate = {2017-01-23},
	date = {2015},
	keywords = {data storytelling, data video, information visualization, Narrative visualization, qualitative analysis},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/K3FZI78A/Amini 等. - 2015 - Understanding Data Videos Looking at Narrative Vi.pdf:application/pdf}
}

@article{berger_cite2vec:_2017,
	title = {cite2vec: Citation-Driven Document Exploration via Word Embeddings},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598667},
	shorttitle = {cite2vec},
	abstract = {Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.},
	pages = {691--700},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Berger, M. and {McDonough}, K. and Seversky, L. M.},
	date = {2017-01},
	keywords = {browsing document collections, citation analysis, citation contexts, citation-driven document exploration, cite2vec, computer vision research papers, Context, data model, data visualisation, Data visualization, Document handling, document projections, document vectors, document visualization, high-dimensional embedding space, Object detection, phrase analogies, search documents, Semantics, Tracking, Two dimensional displays, usage-based document visualization, usage-oriented word-document 2D projection, user-specified concepts, Visualization, word embeddings},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RCNKVXFF/7539398.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GRBH9HMF/Berger 等. - 2017 - cite2vec Citation-Driven Document Exploration via.pdf:application/pdf}
}

@article{hu_visualizing_2017,
	title = {Visualizing Social Media Content with {SentenTree}},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598590},
	abstract = {We introduce {SentenTree}, a novel technique for visualizing the content of unstructured social media text. {SentenTree} displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. {SentenTree} displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. {SentenTree} can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.},
	pages = {621--630},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Hu, M. and Wongsuphasawat, K. and Stasko, J.},
	date = {2017-01},
	keywords = {cloud computing, Context, Games, Layout, Media, Natural Language Processing, node-link diagram, {SentenTree}, social media, social media content visualization, social media posts, social media text collection, social networking (online), Tag clouds, text analysis, Text visualization, Twitter, unstructured social media text, Visualization, word cloud, word clouds, word syntactic ordering, word tree},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/44AXB8SG/7536200.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/A5N4EGJQ/Hu 等. - 2017 - Visualizing Social Media Content with SentenTree.pdf:application/pdf}
}

@article{kim_topiclens:_2017,
	title = {{TopicLens}: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598445},
	shorttitle = {{TopicLens}},
	abstract = {Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. Instead, most such systems are limited to utilizing a fixed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called {TopicLens} that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly. To support this interaction in real time while maintaining view consistency, we propose a novel efficient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with {TopicLens}. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of {TopicLens} using real-world datasets.},
	pages = {151--160},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Kim, M. and Kang, K. and Park, D. and Choo, J. and Elmqvist, N.},
	date = {2017-01},
	keywords = {Analytical models, Computational modeling, document corpus, document image processing, interaction technique, large-scale document collections, learning (artificial intelligence), Lenses, lens interface, magic lens, matrix decomposition, multilevel visual topic exploration, nonnegative matrix factorization, Real-time systems, semisupervised 2D embedding algorithm, stochastic processes, t-distributed stochastic neighbor embedding, Text Analytics, {TopicLens}, topic modeling, topic modeling method, Two dimensional displays, user interfaces, Visual analytics, visualization quality, Web-based visual analytics system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/76WFCRRR/7539597.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WVNBBFFP/Kim 等. - 2017 - TopicLens Efficient Multi-Level Visual Topic Expl.pdf:application/pdf}
}

@article{shen_nameclarifier:_2017,
	title = {{NameClarifier}: A Visual Analytics System for Author Name Disambiguation},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598465},
	shorttitle = {{NameClarifier}},
	abstract = {In this paper, we present a novel visual analytics system called {NameClarifier} to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, {NameClarifier} quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of {NameClarifier}.},
	pages = {141--150},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Shen, Q. and Wu, T. and Yang, H. and Wu, Y. and Qu, H. and Cui, W.},
	date = {2017-01},
	keywords = {Algorithm design and analysis, ambiguous names, analytical reasoning, author name disambiguation, coauthorships, data visualisation, digital libraries, Electronic publishing, Libraries, Metadata, {NameClarifier}, Name disambiguation, publication venues, Uncertainty, Visual analytics, visual analytics system, visual cues, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/A8Z2H4ZP/7534824.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TFR6J9RA/Shen 等. - 2017 - NameClarifier A Visual Analytics System for Autho.pdf:application/pdf}
}

@article{felix_texttile:_2017,
	title = {{TextTile}: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2598447},
	shorttitle = {{TextTile}},
	abstract = {We describe {TextTile}, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. {TextTile} is based on real-world data analysis problems gathered through our interaction with a number of domain experts and provides a general purpose solution to such problems. The system integrates a set of operations that can interchangeably be applied to the structured as well as to unstructured text part of the data to generate useful data summaries. Such summaries are then organized in visual tiles in a grid layout to allow their analysis and comparison. We validate {TextTile} with task analysis, use cases and a user study showing the system can be easily learned and proficiently used to carry out nontrivial tasks.},
	pages = {161--170},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Felix, C. and Pandey, A. V. and Bertini, E.},
	date = {2017-01},
	keywords = {Business, Collaboration, data analysis, data summaries, data visualisation, Data visualization, Exploratory Text Analysis, interactive data visualization tool, Keyword search, knowledge discovery, Medical services, seamless exploratory analysis, structured data analysis, task analysis, text analysis, {TextTile}, Text visualization, unstructured text analysis, Visualization, visual tiles},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/UB7R7IHM/7539549.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CQ39PWXT/Felix 等. - 2017 - TextTile An Interactive Visualization Tool for Se.pdf:application/pdf}
}

@article{kwon_visohc:_2016,
	title = {{VisOHC}: Designing Visual Analytics for Online Health Communities},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467555},
	shorttitle = {{VisOHC}},
	abstract = {Through online health communities ({OHCs}), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by {OHC} administrators. The main challenge of {OHC} administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an {OHC} researcher and two {OHC} administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of {OHC} administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called {VisOHC}, which visualizes individual {OHC} conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of {OHCs}, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using {VisOHC} showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.},
	pages = {71--80},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Kwon, B. C. and Kim, S. H. and Lee, S. and Choo, J. and Huh, J. and Yi, J. S.},
	date = {2016-01},
	keywords = {0, Atmospheric measurements, collapsed boxes, conversation analysis, data analysis, data visualisation, design study, design study,, health care, healthcare, healthcare,, Market research, medical administrative data processing, Message systems, {OHC} conversation threads, online health communities, Particle measurements, Prototypes, thread visualization, {VisOHC} system, Visual analytics, visual design, visual variables},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/63X2S93M/7192683.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/A5MTJ4QC/Kwon 等. - 2016 - VisOHC Designing Visual Analytics for Online Heal.pdf:application/pdf}
}

@article{thom_can_2016,
	title = {Can Twitter Save Lives? A Broad-Scale Study on Visual Social Media Analytics for Public Safety},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2511733},
	shorttitle = {Can Twitter Save Lives?},
	abstract = {The use of social media monitoring for public safety is on the brink of commercialization and practical adoption. To close the gap between research and application, this paper presents results of a two-phase study on visual analytics of social media for public safety. For the first phase, we conducted a large field study, in which 29 practitioners from disaster response and critical infrastructure management were asked to investigate crisis intelligence tasks based on Twitter data recorded during the 2013 German Flood. To this end, the {ScatterBlogs} visual analytics system, a platform that provides reference implementations of tools and techniques popular in research, was given to them as an integrated toolbox. We reviewed the domain experts' individual performances with the system as well as their comments about the usefulness of techniques. In the second phase, we built on this feedback about {ScatterBlogs} in order to sketch out a system and create additional tools specifically adapted to the collected requirements. The performance of the old lab prototype is finally compared against the re-design in a controlled user study.},
	pages = {1816--1829},
	number = {7},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Thom, D. and Krüger, R. and Ertl, T.},
	date = {2016-07},
	keywords = {crisis intelligence task, critical infrastructure management, data visualisation, Data visualization, disaster response, emergency management, evaluation, Floods, Geographic Visualization, Media, Prototypes, public administration, public safety, {ScatterBlogs} visual analytics system, social media, social media monitoring, social networking (online), Twitter, User Study, Visual analytics, visual social media analytics},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/W7HBGKM6/7364284.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/SU32HSPM/Thom 等. - 2016 - Can Twitter Save Lives A Broad-Scale Study on Vis.pdf:application/pdf}
}

@article{beck_visual_2016,
	title = {Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis}},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467757},
	abstract = {Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called {SurVis}, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that {SurVis} meets the initially formulated requirements.},
	pages = {180--189},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Beck, F. and Koch, S. and Weiskopf, D.},
	date = {2016-01},
	keywords = {analytical reasoning process, bibliographic analysis, bibliographic data, bibliographies, Browsers, cognition, data analysis, data visualisation, Data visualization, dissemination, inference mechanisms, Information analysis, information visualization, Internet, Libraries, literature browser, scientific literature collection dissemination, {SurVis} system, Tag clouds, user interface, visual analysis, Visual analytics of documents, Visualization, Web-based system, word-sized sparkline visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/EQWIHDUP/7192633.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MKJNRGUN/Beck 等. - 2016 - Visual Analysis and Dissemination of Scientific Li.pdf:application/pdf}
}

@article{heimerl_citerivers:_2016,
	title = {{CiteRivers}: Visual Analytics of Citation Patterns},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467621},
	shorttitle = {{CiteRivers}},
	abstract = {The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.},
	pages = {190--199},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Heimerl, F. and Han, Q. and Koch, S. and Ertl, T.},
	date = {2016-01},
	keywords = {citation analysis, citation networks, citation patterns, {CiteRivers}, citing publications, clustering, Color, data mining, dataset exploration, data visualisation, Document handling, document metadata, document sets, expert user feedback, interactive visual analysis, interactive visualization approach, Joining processes, knowledge management, Market research, Metadata, scientific documents, scientific information systems, scientific literature, scientific literature collections analysis, scientific literature collections exploration, streamgraph, structure visualization, Tag clouds, textual content, user-steered aggregation, Visual analytics, visual citation analysis, visual document analysis, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RUJ79WP9/7192685.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7DNHEW84/Heimerl 等. - 2016 - CiteRivers Visual Analytics of Citation Patterns.pdf:application/pdf}
}

@article{strobelt_guidelines_2016,
	title = {Guidelines for Effective Usage of Text Highlighting Techniques},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467759},
	abstract = {Semi-automatic text analysis involves manual inspection of text. Often, different text annotations (like part-of-speech or named entities) are indicated by using distinctive text highlighting techniques. In typesetting there exist well-known formatting conventions, such as bold typeface, italics, or background coloring, that are useful for highlighting certain parts of a given text. Also, many advanced techniques for visualization and highlighting of text exist; yet, standard typesetting is common, and the effects of standard typesetting on the perception of text are not fully understood. As such, we surveyed and tested the effectiveness of common text highlighting techniques, both individually and in combination, to discover how to maximize pop-out effects while minimizing visual interference between techniques. To validate our findings, we conducted a series of crowd-sourced experiments to determine: i) a ranking of nine commonly-used text highlighting techniques; ii) the degree of visual interference between pairs of text highlighting techniques; iii) the effectiveness of techniques for visual conjunctive search. Our results show that increasing font size works best as a single highlighting technique, and that there are significant visual interferences between some pairs of highlighting techniques. We discuss the pros and cons of different combinations as a design guideline to choose text highlighting techniques for text viewers.},
	pages = {489--498},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Strobelt, H. and Oelke, D. and Kwon, B. C. and Schreck, T. and Pfister, H.},
	date = {2016-01},
	keywords = {0, background coloring, bold typeface, character sets, Color, crowd-sourced experiments, crowdsourced study, data visualisation, Data visualization, font size, formatting conventions, Image color analysis, Interference, italics, named entities, Natural Language Processing, part-of-speech, pop-out effects, semiautomatic text analysis, standard typesetting, text analysis, text annotation, text annotations, text highlighting techniques, text inspection, visual conjunctive search, visual document analytics, visual interference, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GSZKADE4/7192718.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7RX9MQA4/Strobelt 等. - 2016 - Guidelines for Effective Usage of Text Highlightin.pdf:application/pdf}
}

@article{cho_vairoma:_2016,
	title = {{VAiRoma}: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467971},
	shorttitle = {{VAiRoma}},
	abstract = {Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce {VAiRoma}, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. {VAiRoma} goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, {VAiRoma} allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated {VAiRoma} with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the {VAiRoma} system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on {VAiRoma} was also very positive. In addition, we ran two case studies that demonstrate how {VAiRoma} can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents.},
	pages = {210--219},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Cho, I. and Dou, W. and Wang, D. X. and Sauda, E. and Ribarsky, W.},
	date = {2016-01},
	keywords = {data analysis, data mining, data visualisation, Electronic publishing, Encyclopedias, history, Internet, knowledge discovery, knowledge extraction, Roman history, Text Analytics, {VAiRoma} visual analytics system, Visual analytics, visual interface, Wikipedia, Wikipedia articles},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/5NPKIZ9H/7192676.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6WCAHBAT/Cho 等. - 2016 - VAiRoma A Visual Analytics System for Making Sens.pdf:application/pdf}
}

@article{fulda_timelinecurator:_2016,
	title = {{TimeLineCurator}: Interactive Authoring of Visual Timelines from Unstructured Text},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467531},
	shorttitle = {{TimeLineCurator}},
	abstract = {We present {TimeLineCurator}, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With {TimeLineCurator}, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. {TimeLineCurator} provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate {TimeLineCurator} through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment.},
	pages = {300--309},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Fulda, J. and Brehmel, M. and Munzner, T.},
	date = {2016-01},
	keywords = {1, authoring environment, authoring systems, browser-based authoring tool, Context, data mining, data visualisation, Data visualization, entity extraction error, event data extraction, event data formatting, events curating, events distribution, events editing, interactive authoring, interactive systems, journalism, Manuals, Natural Language Processing, Pipelines, System, temporal references, temporal stories, text analysis, timeline authoring, timeline creation process, timeline curation process, {TimeLineCurator}, timeline material, Timelines, time-oriented data, unstructured text documents, user experience, Visualization, visual timelines},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QR2FQRAR/7192669.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/XU4F9QTA/Fulda 等. - 2016 - TimeLineCurator Interactive Authoring of Visual T.pdf:application/pdf}
}

@article{liu_uncertainty-aware_2016,
	title = {An Uncertainty-Aware Approach for Exploratory Microblog Retrieval},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467554},
	abstract = {Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data.},
	pages = {250--259},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Liu, M. and Liu, S. and Zhu, X. and Liao, Q. and Wei, F. and Pan, S.},
	date = {2016-01},
	keywords = {0, composite visualization, Data models, data visualisation, Data visualization, exploratory microblog retrieval, flow map, graph node, Graph Visualization, hashtags retrieval, high-quality microblog data retrieval, information retrieval, microblog data, Monte Carlo methods, mutual reinforcement model, mutual reinforcement rank, ranking technique, salient posts retrieval, Tagging, Twitter, Uncertainty, uncertainty-aware approach, uncertainty-aware visual analytics approach, uncertainty glyph, uncertainty modeling, uncertainty propagation, uncertainty visualization, Visual analytics, Web sites},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PKS497KB/7192694.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BN6I2KMR/Liu 等. - 2016 - An Uncertainty-Aware Approach for Exploratory Micr.pdf:application/pdf}
}

@article{cao_targetvue:_2016,
	title = {{TargetVue}: Visual Analysis of Anomalous User Behaviors in Online Communication Systems},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467196},
	shorttitle = {{TargetVue}},
	abstract = {Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, {TargetVue}, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, {TargetVue} incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of {TargetVue} through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that {TargetVue} is beneficial to the detection of users with anomalous communication behaviors.},
	pages = {280--289},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Cao, N. and Shi, C. and Lin, S. and Lu, J. and Lin, Y. R. and Lin, C. Y.},
	date = {2016-01},
	keywords = {0, anomalous user behavior, anomaly detection, Context, data analysis, Data models, data visualisation, Data visualization, Electronic mail, Feature extraction, learning (artificial intelligence), machine learning techniques, online communication system, security of data, social bot detection challenge, social media, Targetvue system, triangle grid, Twitter, user behavior, visual analysis, visual analysis system, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/UU96DZPA/7185421.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/C55W6Q9K/Cao 等. - 2016 - TargetVue Visual Analysis of Anomalous User Behav.pdf:application/pdf}
}

@article{mccurdy_poemage:_2016,
	title = {Poemage: Visualizing the Sonic Topology of a Poem},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467811},
	shorttitle = {Poemage},
	abstract = {The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies.},
	pages = {439--448},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {{McCurdy}, N. and Lein, J. and Coles, K. and Meyer, M.},
	date = {2016-01},
	keywords = {1, close reading, Context, data abstraction, data analysis, data visualisation, Data visualization, design studies, digital humanities, disruptive impact technology, distant reading, graph/network data, interactive poem sonic topology exploration, interactive systems, linguistic devices, literary studies, literature, Poemage, poem sonic topology visualization, poetry, Pragmatics, Probes, problem characterization, productive meaning, sound devices, Stress, synoptic evaluation, text analysis, text and document data, text in-depth analysis, textual data analysis, textual data collection, Topology, Visualization, Visualization in the humanities, visualization tool},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DCQGNUI7/7192712.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/T3QRSZZ7/McCurdy 等. - 2016 - Poemage Visualizing the Sonic Topology of a Poem.pdf:application/pdf}
}

@article{liu_online_2016,
	title = {Online Visual Analytics of Text Streams},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2509990},
	abstract = {We present an online visual analytics approach to helping users explore and understand hierarchical topic evolution in high-volume text streams. The key idea behind this approach is to identify representative topics in incoming documents and align them with the existing representative topics that they immediately follow (in time). To this end, we learn a set of streaming tree cuts from topic trees based on user-selected focus nodes. A dynamic Bayesian network model has been developed to derive the tree cuts in the incoming topic trees to balance the fitness of each tree cut and the smoothness between adjacent tree cuts. By connecting the corresponding topics at different times, we are able to provide an overview of the evolving hierarchical topics. A sedimentation-based visualization has been designed to enable the interactive analysis of streaming text data from global patterns to local details. We evaluated our method on real-world datasets and the results are generally favorable.},
	pages = {2451--2466},
	number = {11},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Liu, S. and Yin, J. and Wang, X. and Cui, W. and Cao, K. and Pei, J.},
	date = {2016-11},
	keywords = {adjacent tree cuts, Algorithm design and analysis, Bayes methods, belief networks, Clustering algorithms, data analysis, data visualisation, Data visualization, dynamic Bayesian network model, Electronic mail, evolutionary tree clustering, global patterns, Heuristic algorithms, hierarchical topic evolution, high-volume text streams, interactive analysis, online visual analytics, sedimentation-based visualization, streaming text data, streaming topic visualization, streaming tree cut, streaming tree cuts, text analysis, topic trees, user-selected focus nodes, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QBJ5WP3B/7360233.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/8QFJ6VKD/Liu 等. - 2016 - Online Visual Analytics of Text Streams.pdf:application/pdf}
}

@article{janicke_interactive_2016,
	title = {Interactive Visual Profiling of Musicians},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467620},
	abstract = {Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians' attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology.},
	pages = {200--209},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Jänicke, S. and Focht, J. and Scheuermann, G.},
	date = {2016-01},
	keywords = {0, Bavarian Musicians Encyclopedia Online, collaborative digital humanities project, data analysis, Databases, data visualisation, Data visualization, digital humanities, interactive visual profiling, music, musicians, musicians database visualization, musicologists, musicology, profiling system, Social network services, Uncertainty, Visual analytics, visual analytics profiling system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BMQSU7NI/7192680.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/AW5NZVX9/Jänicke 等. - 2016 - Interactive Visual Profiling of Musicians.pdf:application/pdf}
}

@article{hinrichs_speculative_2016,
	title = {Speculative Practices: Utilizing {InfoVis} to Explore Untapped Literary Collections},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467452},
	shorttitle = {Speculative Practices},
	abstract = {In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While {InfoVis} has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an {InfoVis} perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to {InfoVis}, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes.},
	pages = {429--438},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Hinrichs, U. and Forlini, S. and Moynihan, B.},
	date = {2016-01},
	keywords = {0, Context, cultural collections, Cultural differences, data visualisation, Data visualization, digital humanities, Fans, humanities, hypotheses testing, information visualization, {InfoVis}, Interlinked Visualization, literary collections, literary studies, Metadata, preliminary interpretation process, Science Fiction, speculative thinking, Speculative Wanderverse tool, statistical analysis, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/X7CERXZ5/7192666.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WNAXUDI4/Hinrichs 等. - 2016 - Speculative Practices Utilizing InfoVis to Explor.pdf:application/pdf}
}

@article{lu_exploring_2016,
	title = {Exploring Evolving Media Discourse Through Event Cueing},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467991},
	abstract = {Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa.},
	pages = {220--229},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Lu, Y. and Steptoe, M. and Burke, S. and Wang, H. and Tsai, J. Y. and Davulcu, H. and Montgomery, D. and Corman, S. R. and Maciejewski, R.},
	date = {2016-01},
	keywords = {Africa, Analytical models, Context, data visualisation, Document handling, event cueing, Event detection, Lenses, Media, Media Analysis, media discourse, media documents, Meteorology, microblogs, online news, Rhetoric, time series, Time series analysis, Visual analytics, visual exploration, Web sites},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/R474BD7K/7192705.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/JXD6ZCTK/Lu 等. - 2016 - Exploring Evolving Media Discourse Through Event C.pdf:application/pdf}
}

@article{chi_morphable_2015,
	title = {Morphable Word Clouds for Time-Varying Text Data Visualization},
	volume = {21},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2440241},
	abstract = {A word cloud is a visual representation of a collection of text documents that uses various font sizes, colors, and spaces to arrange and depict significant words. The majority of previous studies on time-varying word clouds focuses on layout optimization and temporal trend visualization. However, they do not fully consider the spatial shapes and temporal motions of word clouds, which are important factors for attracting people's attention and are also important cues for human visual systems in capturing information from time-varying text data. This paper presents a novel method that uses rigid body dynamics to arrange multi-temporal word-tags in a specific shape sequence under various constraints. Each word-tag is regarded as a rigid body in dynamics. With the aid of geometric, aesthetic, and temporal coherence constraints, the proposed method can generate a temporally morphable word cloud that not only arranges word-tags in their corresponding shapes but also smoothly transforms the shapes of word clouds overtime, thus yielding a pleasing time-varying visualization. Using the proposed frame-by-frame and morphable word clouds, people can observe the overall story of a time-varying text data from the shape transition, and people can also observe the details from the word clouds in frames. Experimental results on various data demonstrate the feasibility and flexibility of the proposed method in morphable word cloud generation. In addition, an application that uses the proposed word clouds in a simulated exhibition demonstrates the usefulness of the proposed method.},
	pages = {1415--1426},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Chi, M. T. and Lin, S. S. and Chen, S. Y. and Lin, C. H. and Lee, T. Y.},
	date = {2015-12},
	keywords = {0, data analysis, data visualisation, Data visualization, digital storytelling, Digital systems, frame-by-frame word clouds, information visualization, Interpolation, Market research, multitemporal word-tag arrangement, rigid body dynamics, shape sequence, Tag clouds, temporally morphable word cloud, text analysis, text documents visual representation, Text mining, time-varying systems, time-varying text data, time-varying text data visualization, Virtual reality, word cloud},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WNN8BHKW/7118241.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QEZDDQ5R/Chi 等. - 2015 - Morphable Word Clouds for Time-Varying Text Data V.pdf:application/pdf}
}

@article{gad_themedelta:_2015,
	title = {{ThemeDelta}: Dynamic Segmentations over Temporal Topic Models},
	volume = {21},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2388208},
	shorttitle = {{ThemeDelta}},
	abstract = {We present {ThemeDelta}, a visual analytics system for extracting and visualizing temporal trends, clustering, and reorganization in time-indexed textual datasets. {ThemeDelta} is supported by a dynamic temporal segmentation algorithm that integrates with topic modeling algorithms to identify change points where significant shifts in topics occur. This algorithm detects not only the clustering and associations of keywords in a time period, but also their convergence into topics (groups of keywords) that may later diverge into new groups. The visual representation of {ThemeDelta} uses sinuous, variable-width lines to show this evolution on a timeline, utilizing color for categories, and line width for keyword strength. We demonstrate how interaction with {ThemeDelta} helps capture the rise and fall of topics by analyzing archives of historical newspapers, of U.S. presidential campaign speeches, and of social messages collected through {iNeighbors}, a web-based social website. {ThemeDelta} is evaluated using a qualitative expert user study involving three researchers from rhetoric and history using the historical newspapers corpus.},
	pages = {672--685},
	number = {5},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Gad, S. and Javed, W. and Ghani, S. and Elmqvist, N. and Ewing, T. and Hampton, K. N. and Ramakrishnan, N.},
	date = {2015-05},
	keywords = {data analysis, Data visualization, dynamic temporal segmentation algorithm, Heuristic algorithms, historical newspapers, {iNeighbors}, keyword strength, Language models, Layout, Market research, Tag clouds, temporal topic models, text analysis, Text Analytics, {ThemeDelta}, time-indexed textual datasets, time-series segmentation, topic modeling algorithms, {US} presidential campaign speeches, Visual analytics, visual analytics system, visual representations, Web-based social Website, Web sites},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/EN8P4J7U/7001093.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/MX3Q5WX8/Gad 等. - 2015 - ThemeDelta Dynamic Segmentations over Temporal To.pdf:application/pdf}
}

@article{isaacs_footprints:_2014,
	title = {Footprints: A Visual Search Tool that Supports Discovery and Coverage Tracking},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346743},
	shorttitle = {Footprints},
	abstract = {Searching a large document collection to learn about a broad subject involves the iterative process of figuring out what to ask, filtering the results, identifying useful documents, and deciding when one has covered enough material to stop searching. We are calling this activity “discoverage,” discovery of relevant material and tracking coverage of that material. We built a visual analytic tool called Footprints that uses multiple coordinated visualizations to help users navigate through the discoverage process. To support discovery, Footprints displays topics extracted from documents that provide an overview of the search space and are used to construct searches visuospatially. Footprints allows users to triage their search results by assigning a status to each document (To Read, Read, Useful), and those status markings are shown on interactive histograms depicting the user's coverage through the documents across dates, sources, and topics. Coverage histograms help users notice biases in their search and fill any gaps in their analytic process. To create Footprints, we used a highly iterative, user-centered approach in which we conducted many evaluations during both the design and implementation stages and continually modified the design in response to feedback.},
	pages = {1793--1802},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Isaacs, E. and Damico, K. and Ahern, S. and Bart, E. and Singhal, M.},
	date = {2014-12},
	keywords = {analytic process, coverage histograms, coverage tracking, data analysis, data visualisation, discoverage, discoverage activity, discoverage process, discovery search visualization, discovery tracking, document collection searching, document triage, Feature extraction, Footprints, Histograms, information filtering, Information filters, interactive histograms, iterative methods, iterative process, search space, Space exploration, text analysis, topic extraction, Tracking, user-centered approach, user coverage, visual analytic tool, visual cues, visual search tool},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H3CVG3NR/6875947.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/X5R7SS6J/Isaacs 等. - 2014 - Footprints A Visual Search Tool that Supports Dis.pdf:application/pdf}
}

@article{gomez-nieto_similarity_2014,
	title = {Similarity Preserving Snippet-Based Visualization of Web Search Results},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.242},
	abstract = {Internet users are very familiar with the results of a search query displayed as a ranked list of snippets. Each textual snippet shows a content summary of the referred document (or webpage) and a link to it. This display has many advantages, for example, it affords easy navigation and is straightforward to interpret. Nonetheless, any user of search engines could possibly report some experience of disappointment with this metaphor. Indeed, it has limitations in particular situations, as it fails to provide an overview of the document collection retrieved. Moreover, depending on the nature of the query for example, it may be too general, or ambiguous, or ill expressed the desired information may be poorly ranked, or results may contemplate varied topics. Several search tasks would be easier if users were shown an overview of the returned documents, organized so as to reflect how related they are, content wise. We propose a visualization technique to display the results of web queries aimed at overcoming such limitations. It combines the neighborhood preservation capability of multidimensional projections with the familiar snippet-based representation by employing a multidimensional projection to derive two-dimensional layouts of the query search results that preserve text similarity relations, or neighborhoods. Similarity is computed by applying the cosine similarity over a "bag-of-wordsâ' vector representation of collection built from the snippets. If the snippets are displayed directly according to the derived layout, they will overlap considerably, producing a poor visualization. We overcome this problem by defining an energy functional that considers both the overlapping among snippets and the preservation of the neighborhood structure as given in the projected layout. Minimizing this energy functional provides a neighborhood preserving two-dimensional arrangement of the textual snippets with minimum overlap. The resulting visualization conveys both a - lobal view of the query results and visual groupings that reflect related results, as illustrated in several examples shown.},
	pages = {457--470},
	number = {3},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Gomez-Nieto, E. and Roman, F. S. and Pagliosa, P. and Casaca, W. and Helou, E. S. and Oliveira, M. C. F. de and Nonato, L. G.},
	date = {2014-03},
	keywords = {data visualisation, document collection retrieval, Document handling, energy functional, Internet, Layout, Multidimensional projection, Navigation, Optimization, query processing, query search, referred document, search engines, search query, similarity preserving snippet based visualization, text similarity, textual snippet, Vectors, Visualization, Web page, Web pages, Web queries, Web search results, web search visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/22STBZF4/6629989.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/EZDKD68T/Gomez-Nieto 等. - 2014 - Similarity Preserving Snippet-Based Visualization .pdf:application/pdf}
}

@article{sun_evoriver:_2014,
	title = {{EvoRiver}: Visual Analysis of Topic Coopetition on Social Media},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346919},
	shorttitle = {{EvoRiver}},
	abstract = {Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design {EvoRiver}, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).},
	pages = {1753--1762},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Sun, G. and Wu, Y. and Liu, S. and Peng, T. Q. and Zhu, J. J. H. and Liang, R.},
	date = {2014-12},
	keywords = {1, close functional approximation, Cooperation, coopetition distraction effects, coopetition recruitment, Data visualization, {EvoRiver}, indepth analysis, information diffusion, information propagation, Internet, Media, public attention, social media, social networking (online), Social network services, time-based visualization, topic coopetition, Twitter data sets, Visual analytics, visual analytics system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WUHXNKKI/6875992.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/V4FTKT6C/Sun 等. - 2014 - EvoRiver Visual Analysis of Topic Coopetition on .pdf:application/pdf}
}

@article{zhao_x0023;fluxflow:_2014,
	title = {\#x0023;{FluxFlow}: Visual Analysis of Anomalous Information Spreading on Social Media},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346922},
	shorttitle = {\#x0023;{FluxFlow}},
	abstract = {We present {FluxFlow}, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. {FluxFlow} incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated {FluxFlow} with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.},
	pages = {1773--1782},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Zhao, J. and Cao, N. and Wen, Z. and Song, Y. and Lin, Y. R. and Collins, C.},
	date = {2014-12},
	keywords = {\#{FluxFlow}, 1, advanced machine learning algorithms, anomalous information behaviors, anomalous information spreading, anomalous retweeting threads, anomaly detection, back-end anomaly detection model, crowd messages, data analysis, data analyst capability, data visualisation, Data visualization, decision making, decision-making, deeper analysis, dynamic crowd behaviors, Facebook, Feature extraction, front-end interactive visualizations, Hurricane Sandy, information visualization, Instruction sets, interactive visual analysis system, learning (artificial intelligence), machine learning, Media, Message systems, quantitative measurements, Retweeting threads, social media, social media Websites, social networking (online), Social network services, social signals, Twitter, Visual analytics},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/K6G7GM4T/6876013.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CHSXEGGJ/Zhao 等. - 2014 - #x0023\;FluxFlow Visual Analysis of Anomalous Info.pdf:application/pdf}
}

@article{brehmer_overview:_2014,
	title = {Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346431},
	shorttitle = {Overview},
	abstract = {For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system “in the wild”, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of “exploring” a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.},
	pages = {2271--2280},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Brehmer, M. and Ingram, S. and Stray, J. and Munzner, T.},
	date = {2014-12},
	keywords = {0, data mining, data summarization, data visualisation, Data visualization, design study, document clustering, document collection analysis, Document handling, document tagging, document visualization, Encoding, Freedom of Information Act request, frequently-used language, graphical user interfaces, interaction techniques, in-the-wild visualization system, investigative journalism, investigative journalists, iterative process, multiple newsworthy stories, Overview, pattern clustering, published story production, query processing, self-initiated journalists, standard text search, task abstractions, task and requirements analysis, text analysis, text and document data, Text mining, visual document mining tool adoption, visual document mining tool analysis, visual document mining tool design, visual encoding, visualization design methodology},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/VDA5NTK5/6875900.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/K2KAH43N/Brehmer 等. - 2014 - Overview The Design, Adoption, and Analysis of a .pdf:application/pdf}
}

@article{koch_varifocalreader_2014,
	title = {{VarifocalReader} \#x2014; In-Depth Visual Analysis of Large Text Documents},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346677},
	abstract = {Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With {VarifocalReader} we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, {VarifocalReader} supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.},
	pages = {1723--1732},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Koch, S. and John, M. and Wörner, M. and Müller, A. and Ertl, T.},
	date = {2014-12},
	keywords = {data mining, data visualisation, Data visualization, distant reading, document analysis, Document handling, focus-context techniques, in-depth visual analysis, interactive systems, intermediate text levels, learning (artificial intelligence), literary analysis, machine learning, machine learning techniques, Natural Language Processing, Navigation, Tag clouds, text analysis, text documents, Text mining, varifocalreader, visual abstraction, Visual analytics},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/I848B8ZG/6875959.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/9BVWC29P/Koch 等. - 2014 - VarifocalReader #x2014\; In-Depth Visual Analysis o.pdf:application/pdf}
}

@article{cui_how_2014,
	title = {How Hierarchical Topics Evolve in Large Text Corpora},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346433},
	abstract = {Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.},
	pages = {2281--2290},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Cui, W. and Liu, S. and Wu, Z. and Wei, H.},
	date = {2014-12},
	keywords = {0, Algorithm design and analysis, complex evolutionary patterns, Context awareness, data transformation, Data visualization, Document handling, document organisation, evolutionary tree clustering, evolutionary tree cut algorithm, hierarchical topics, Hierarchical topic visualization, interactive visual text analysis, large text corpora, stable layout algorithm, text analysis, Text mining, time based visualization, topic trees sequence, tree cut},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/Z7FQF5XC/6875938.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DMSJFVXS/Cui 等. - 2014 - How Hierarchical Topics Evolve in Large Text Corpo.pdf:application/pdf}
}

@article{wu_opinionflow:_2014,
	title = {{OpinionFlow}: Visual Analysis of Opinion Diffusion on Social Media},
	volume = {20},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2014.2346920},
	shorttitle = {{OpinionFlow}},
	abstract = {It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called {OpinionFlow} to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of {OpinionFlow}.},
	pages = {1763--1772},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Wu, Y. and Liu, S. and Yan, K. and Liu, M. and Wu, F.},
	date = {2014-12},
	keywords = {1, business intelligence, data analysis, data visualisation, Data visualization, government, influence estimation, Information analysis, information diffusion model, kernel density estimation, level-of-detail, Media, opinion diffusion, opinion diffusion model, {OpinionFlow}, opinion flow, opinion flow visualization, opinion propagation patterns, opinion visualization, public opinion diffusion, selective exposure theory, social media, social networking (online), Social network services, social sciences computing, stacked tree, Twitter, visual analysis system, Visual analytics},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TK8J2GG4/6876032.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/I2BADTAC/Wu 等. - 2014 - OpinionFlow Visual Analysis of Opinion Diffusion .pdf:application/pdf}
}

@article{gorg_combining_2013,
	title = {Combining Computational Analyses and Interactive Visualization for Document Exploration and Sensemaking in Jigsaw},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.324},
	abstract = {Investigators across many disciplines and organizations must sift through large collections of text documents to understand and piece together information. Whether they are fighting crime, curing diseases, deciding what car to buy, or researching a new field, inevitably investigators will encounter text documents. Taking a visual analytics approach, we integrate multiple text analysis algorithms with a suite of interactive visualizations to provide a flexible and powerful environment that allows analysts to explore collections of documents while sensemaking. Our particular focus is on the process of integrating automated analyses with interactive visualizations in a smooth and fluid manner. We illustrate this integration through two example scenarios: An academic researcher examining {InfoVis} and {VAST} conference papers and a consumer exploring car reviews while pondering a purchase decision. Finally, we provide lessons learned toward the design and implementation of visual analytics systems for document exploration and understanding.},
	pages = {1646--1663},
	number = {10},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Görg, C. and Liu, Z. and Kihm, J. and Choo, J. and Park, H. and Stasko, J.},
	date = {2013-10},
	keywords = {academic researcher, Algorithm design and analysis, automated analysis, computational analysis, Computational modeling, data visualisation, Data visualization, document analysis, document exploration, exploratory search, information retrieval, information seeking, information visualization, {InfoVis} conference papers, interactive systems, interactive visualization, Jigsaw, Measurement, purchase decision, sensemaking, Tag clouds, text analysis, text analysis algorithm, text document collection, {VAST} conference papers, Visual analytics, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/TDJHD4QP/6392833.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FE7DJQ4P/Görg 等. - 2013 - Combining Computational Analyses and Interactive V.pdf:application/pdf}
}

@article{bosch_scatterblogs2:_2013,
	title = {{ScatterBlogs}2: Real-Time Monitoring of Microblog Messages through User-Guided Filtering},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.186},
	shorttitle = {{ScatterBlogs}2},
	abstract = {The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest {ScatterBlogs}2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.},
	pages = {2022--2031},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bosch, H. and Thom, D. and Heimerl, F. and Püttmann, E. and Koch, S. and Krüger, R. and Wörner, M. and Ertl, T.},
	date = {2013-12},
	keywords = {Algorithms, Blogging, Blogs, Computer Graphics, Computer Systems, co-occurrence statistical distribution, decision making, emergency management, emergency management scenarios, filter construction, information filtering, Information filters, information retrieval, Information Storage and Retrieval, information visualization, Labeling, live monitoring, message retrieval, meta data, metadata restrictions, Microblog analysis, microblog feeds, microblog message real-time monitoring, microblog posts, pattern classification, query construction, query creation, query processing, Real-time systems, Reproducibility of Results, {ScatterBlogs}2, Sensitivity and Specificity, situational awareness, social media, social media monitoring, social networking (online), Social network services, Software, Spatiotemporal phenomena, statistical distributions, supervised classification, task-tailored message filters, term statistical distribution, Text Analytics, text classification, time-critical tasks, Twitter, User-Computer Interface, user-defined keyword queries, user-guided filtering, Visual analytics},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/45MZ3ZVU/6634195.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4Z6E798H/Bosch 等. - 2013 - ScatterBlogs2 Real-Time Monitoring of Microblog M.pdf:application/pdf}
}

@article{choo_utopian:_2013,
	title = {{UTOPIAN}: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.212},
	shorttitle = {{UTOPIAN}},
	abstract = {Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation ({LDA}) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, {LDA} cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called {UTOPIAN} (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, {UTOPIAN} enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of {UTOPIAN} via several usage scenarios with real-world document corpuses such as {InfoVis}/{VAST} paper data set and product review data sets.},
	pages = {1992--2001},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Choo, J. and Lee, C. and Reddy, C. K. and Park, H.},
	date = {2013-12},
	keywords = {Analytical models, Artificial Intelligence, Computational modeling, Computer Graphics, Computer Simulation, Context modeling, data analysis, data visualisation, flexible visual analytics system, Image Enhancement, Image Interpretation, Computer-Assisted, Information Storage and Retrieval, interactive clustering, Interactive states, interactive systems, latent Dirichlet allocation, matrix decomposition, Models, Statistical, Natural Language Processing, nonnegative matrix factorization, Pattern Recognition, Automated, probabilistic graphical modeling, real-world document corpuses, reliable visual analytics system, semisupervised formulation, Software, text analysis, Text Analytics, text document collection analysis, topic modeling, topic modeling method, topic modeling techniques, user-driven manner, user-driven topic modeling based on interactive nonnegative matrix factorization, user feedback, {UTOPIAN}, Visual analytics, visual text analytics},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QSFH9B2M/6634167.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CAHUAEGM/Choo 等. - 2013 - UTOPIAN User-Driven Topic Modeling Based on Inter.pdf:application/pdf}
}

@article{zhao_interactive_2013,
	title = {Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.167},
	abstract = {Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present {PivotSlice}, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, {PivotSlice} allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. {PivotSlice} further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated {PivotSlice} through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of {PivotSlice} using a scenario of exploring a repository of information visualization literature.},
	pages = {2080--2089},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Zhao, J. and Collins, C. and Chevalier, F. and Balakrishnan, R.},
	date = {2013-12},
	keywords = {Algorithms, Computer Graphics, Database Management Systems, Databases, Factual, data exploration, data integration, data mining, data visualisation, Data visualization, direct manipulation metaphor, dynamic query, explicit relational references, explicit relations, faceted browsing, faceted dataset, Faceted searches, graphical interaction history, implicit relations, Information filters, information visualization, Interaction, live search, Market research, multifocus multiscale tabular view, network exploration, online data integration, {PivotSlice} interactive visualization technique, sensemaking process, smoothly animated visual state transitions, User-Computer Interface, Visual analytics, visual exploration process},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/65JPKKD6/6634163.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FN8UG2QA/Zhao 等. - 2013 - Interactive Exploration of Implicit and Explicit R.pdf:application/pdf}
}

@article{xu_visual_2013,
	title = {Visual Analysis of Topic Competition on Social Media},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.221},
	abstract = {How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing {ThemeRiver} with storyline style visualization. {ThemeRiver} shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.},
	pages = {2012--2021},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Xu, P. and Wu, Y. and Wei, E. and Peng, T. Q. and Liu, S. and Zhu, J. J. H. and Qu, H.},
	date = {2013-12},
	keywords = {2012 United States presidential election, agenda-setting, Algorithms, Computer Graphics, data mining, data visualisation, Data visualization, Image Interpretation, Computer-Assisted, information diffusion, information diffusion process, information propagation, Mathematical model, metaphoric interpretation, Occupy Wall Street movement, opinion leaders, public agenda, public attention competition, Recruitment, Reproducibility of Results, Sensitivity and Specificity, social aspects, social media, Social media visuaization, social networking (online), Social network services, storyline style visualization, {ThemeRiver}, timeline visualization, topical aspects, topic competition, topic competition model, topic competitiveness, Tweets, User-Computer Interface, visual analysis techniques, Visual analytics, visual design},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/3IGKFD4Z/6634134.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/39QIXZCM/Xu 等. - 2013 - Visual Analysis of Topic Competition on Social Med.pdf:application/pdf}
}

@article{huron_visual_2013,
	title = {Visual Sedimentation},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.227},
	abstract = {We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, {RSS}, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.},
	pages = {2446--2455},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Huron, S. and Vuillemot, R. and Fekete, J. D.},
	date = {2013-12},
	keywords = {Algorithms, chronological order, Computer Graphics, Computer Simulation, data stream, data stream visualization, data visualisation, Data visualization, design, Design methodology, dynamic data, dynamic visualization, force model, Geologic Sediments, Image Enhancement, Information Storage and Retrieval, information visualization, metaphor, metaphor design space, Models, Theoretical, real time, Real-time systems, Reproducibility of Results, sedimentation process, Sediments, Sensitivity and Specificity, User-Computer Interface, visual sedimentation design metaphor},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RZ8M9FPZ/6634152.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/5MM2GSXM/Huron 等. - 2013 - Visual Sedimentation.pdf:application/pdf}
}

@article{dou_hierarchicaltopics:_2013,
	title = {{HierarchicalTopics}: Visually Exploring Large Text Collections Using Topic Hierarchies},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.162},
	shorttitle = {{HierarchicalTopics}},
	abstract = {Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - {HierarchicalTopic} ({HT}). {HT} integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate {HT}, we present a case study that showcases how {HierarchicalTopics} aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the {HT} leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of {HierarchicalTopics}.},
	pages = {2002--2011},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Dou, W. and Yu, L. and Wang, X. and Ma, Z. and Ribarsky, W.},
	date = {2013-12},
	keywords = {Algorithm design and analysis, Algorithms, Analytical models, Artificial Intelligence, computational algorithm, computational complexity, Computational modeling, Computer Graphics, data visualisation, Documentation, {HierarchicalTopic}, Hierarchical topic representation, hierarchical topic structure, Image Enhancement, Image Interpretation, Computer-Assisted, Information Storage and Retrieval, interactive visual interface, interactive visualizations, Natural Language Processing, Pattern Recognition, Automated, rose tree, Software, text analysis, text collections, text corpora, Text mining, textual collections, topic-based text summarization methods, topic-based visualizations, topic groups, topic hierarchy, topic modeling, topic rose tree, trees (mathematics), User-Computer Interface, user feedback, user interactions, user interfaces, Visual analytics, visual analytics system, vocabulary},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IXU634N7/6634160.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/8AUCU5N8/Dou 等. - 2013 - HierarchicalTopics Visually Exploring Large Text .pdf:application/pdf}
}

@article{angus_conceptual_2012,
	title = {Conceptual Recurrence Plots: Revealing Patterns in Human Discourse},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2011.100},
	shorttitle = {Conceptual Recurrence Plots},
	abstract = {Human discourse contains a rich mixture of conceptual information. Visualization of the global and local patterns within this data stream is a complex and challenging problem. Recurrence plots are an information visualization technique that can reveal trends and features in complex time series data. The recurrence plot technique works by measuring the similarity of points in a time series to all other points in the same time series and plotting the results in two dimensions. Previous studies have applied recurrence plotting techniques to textual data; however, these approaches plot recurrence using term-based similarity rather than conceptual similarity of the text. We introduce conceptual recurrence plots, which use a model of language to measure similarity between pairs of text utterances, and the similarity of all utterances is measured and displayed. In this paper, we explore how the descriptive power of the recurrence plotting technique can be used to discover patterns of interaction across a series of conversation transcripts. The results suggest that the conceptual recurrence plotting technique is a useful tool for exploring the structure of human discourse.},
	pages = {988--997},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Angus, D. and Smith, A. and Wiles, J.},
	date = {2012-06},
	keywords = {communication, complex time series data, Computer Graphics, concept, Concept map, conceptual information, conceptual recurrence plot technique, conversation analysis, conversation transcripts, Databases, Factual, data stream, data visualisation, Data visualization, global-local pattern visualization, human discourse, Humans, Image color analysis, information visualization technique, interaction pattern discovery, language modelling, Narration, Natural Language Processing, Pain, Pattern Recognition, Automated, pattern revealing, plotting, point similarity measurement, recurrence, Semantics, Speech, surgery, term-based similarity, text analysis, text analysis., text utterances, time series, Time series analysis},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/5MHK4BQM/5887327.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/532BSFF7/Angus 等. - 2012 - Conceptual Recurrence Plots Revealing Patterns in.pdf:application/pdf}
}

@article{luo_eventriver:_2012,
	title = {{EventRiver}: Visually Exploring Text Collections with Temporal References},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.225},
	shorttitle = {{EventRiver}},
	abstract = {Many text collections with temporal references, such as news corpora and weblogs, are generated to report and discuss real life events. Thus, event-related tasks, such as detecting real life events that drive the generation of the text documents, tracking event evolutions, and investigating reports and commentaries about events of interest, are important when exploring such text collections. To incorporate and leverage human efforts in conducting such tasks, we propose a novel visual analytics approach named {EventRiver}. {EventRiver} integrates event-based automated text analysis and visualization to reveal the events motivating the text generation and the long term stories they construct. On the visualization, users can interactively conduct tasks such as event browsing, tracking, association, and investigation. A working prototype of {EventRiver} has been implemented for exploring news corpora. A set of case studies, experiments, and a preliminary user test have been conducted to evaluate its effectiveness and efficiency.},
	pages = {93--105},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Luo, D. and Yang, J. and Krstajic, M. and Ribarsky, W. and Keim, D.},
	date = {2012-01},
	keywords = {Bismuth, Cluster Analysis, clustering., Clustering algorithms, Computer Graphics, Context, Database Management Systems, Databases, Factual, data visualisation, event, event-based automated text analysis, event browsing, event-related tasks, {EventRiver}, Humans, information visualization, Mass Media, Models, Theoretical, news corpora, Semantics, temporal references, text, text analysis, text generation, Text visualization, Time Factors, topic, User-Computer Interface, Visual analytics, visual analytics approach, Visualization, visually exploring text collections, Weblogs},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PQRXDR8E/5611507.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CDE487V5/Luo 等. - 2012 - EventRiver Visually Exploring Text Collections wi.pdf:application/pdf}
}

@article{heimerl_visual_2012,
	title = {Visual Classifier Training for Text Document Retrieval},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.277},
	abstract = {Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.},
	pages = {2839--2848},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Heimerl, F. and Koch, S. and Bosch, H. and Ertl, T.},
	date = {2012-12},
	keywords = {1, active learning, Classification, classification methods, data visualisation, filter criteria, Human computer interaction, information retrieval, interactive classifier training, interactive systems, interactive visualization, iterative feedback loops, iterative methods, labeled documents, learning (artificial intelligence), Learning systems, machine learning, pattern classification, Performance evaluation, query processing, search queries, text analysis, text document retrieval, text search, Training data, user controlled classification methods, user evaluation, Visual analytics, visual classifier training},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WUB95X68/6327290.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WVHXSP58/Heimerl 等. - 2012 - Visual Classifier Training for Text Document Retri.pdf:application/pdf}
}

@article{zhao_facilitating_2012,
	title = {Facilitating Discourse Analysis with Interactive Visualization},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.226},
	abstract = {A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present {DAViewer}, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of {DAViewer}. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.},
	pages = {2639--2648},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Zhao, J. and Chevalier, F. and Collins, C. and Balakrishnan, R.},
	date = {2012-12},
	keywords = {Algorithm design and analysis, computational linguisitics, computational linguistics, computational linguistics researchers, data structures, data visualisation, Data visualization, {DAViewer}, dialogue generation, discourse analysis, discourse parser, Discourse structure, document, Document handling, grammars, Image color analysis, interaction techniques, interactive systems, interactive visualization system, iterative methods, iterative user-centered design process, Natural Language Processing, natural language processing system, parsing algorithms, Prototypes, question answering, rhetorical structure tree, Standards, text summarization, tree comparison, tree data structures, Visual analytics, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/D4RSWPXS/6327270.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/VDN9Z87X/Zhao 等. - 2012 - Facilitating Discourse Analysis with Interactive V.pdf:application/pdf}
}

@article{cao_whisper:_2012,
	title = {Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.291},
	shorttitle = {Whisper},
	abstract = {When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, “Whisper”, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.},
	pages = {2649--2658},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Cao, N. and Lin, Y. R. and Sun, X. and Lazer, D. and Liu, S. and Qu, H.},
	date = {2012-12},
	keywords = {1, contagion, data mining, data visualisation, Diffusion processes, flux line-drawing algorithm, focused diffusion series, information diffusion, information visualization, Media, microblogging, Monitoring, Real-time systems, social media, social networking (online), Social network services, social-spatial extent, spatial hierarchical layout, spatial pattern, spatiotemporal patterns, spatiotemporal process, sunflower metaphor, temporal pattern, temporal trend, Twitter, visualization design, Whisper},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/8DHSNW4F/6327271.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DP39UDNE/Cao 等. - 2012 - Whisper Tracing the Spatiotemporal Process of Inf.pdf:application/pdf}
}

@article{riehmann_wordgraph:_2012,
	title = {{WORDGRAPH}: Keyword-in-Context Visualization for {NETSPEAK}'s Wildcard Search},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.96},
	shorttitle = {{WORDGRAPH}},
	abstract = {The {WORDGRAPH} helps writers in visually choosing phrases while writing a text. It checks for the commonness of phrases and allows for the retrieval of alternatives by means of wildcard queries. To support such queries, we implement a scalable retrieval engine, which returns high-quality results within milliseconds using a probabilistic retrieval strategy. The results are displayed as {WORDGRAPH} visualization or as a textual list. The graphical interface provides an effective means for interactive exploration of search results using filter techniques, query expansion, and navigation. Our observations indicate that, of three investigated retrieval tasks, the textual interface is sufficient for the phrase verification task, wherein both interfaces support context-sensitive word choice, and the {WORDGRAPH} best supports the exploration of a phrase's context or the underlying corpus. Our user study confirms these observations and shows that {WORDGRAPH} is generally the preferred interface over the textual result list for queries containing multiple wildcards.},
	pages = {1411--1423},
	number = {9},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Riehmann, P. and Gruendl, H. and Potthast, M. and Trenkmann, M. and Stein, B. and Froehlich, B.},
	date = {2012-09},
	keywords = {data visualisation, Engines, filter techniques, Google, graphical interface, Indexes, information retrieval, information visualization, interactive exploration, keyword-in-context visualization, Layout, Navigation, {NETSPEAK} wildcard search, phrase context, probabilistic retrieval strategy, probability, query expansion, query navigation, scalable retrieval engine, Text visualization, underlying corpus, Visualization, visually choosing phrases, visual queries, Web n-grams, wildcard queries, wildcard search., {WORDGRAPH}},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4JZ4MARW/6175895.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6CV3HU7R/Riehmann 等. - 2012 - WORDGRAPH Keyword-in-Context Visualization for NE.pdf:application/pdf}
}

@article{afzal_spatial_2012,
	title = {Spatial Text Visualization Using Automatic Typographic Maps},
	volume = {18},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2012.264},
	abstract = {We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the {OpenStreetMap} project into typographic maps for any region.},
	pages = {2556--2564},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Afzal, S. and Maciejewski, R. and Jang, Y. and Elmqvist, N. and Ebert, D. S.},
	date = {2012-12},
	keywords = {automatic typographic maps, cartography, Cities and towns, computational geometry, crime rate, data visualisation, Data visualization, demographic data, geographic map, Geospatial analysis, Geovisualization, graphical features, label placement, {OpenStreetMap} project, polygons, polylines, Rendering (computer graphics), spatial data, Spatial databases, spatial text visualization, text data, Text visualization, traffic density, user-defined visual attributes, visual representation, Web service, Web services},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PCDKTFQ7/6327261.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RS4VZEJD/Afzal 等. - 2012 - Spatial Text Visualization Using Automatic Typogra.pdf:application/pdf}
}

@article{krstajic_cloudlines:_2011,
	title = {{CloudLines}: Compact Display of Event Episodes in Multiple Time-Series},
	volume = {17},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2011.179},
	shorttitle = {{CloudLines}},
	abstract = {We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.},
	pages = {2432--2439},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Krstajic, M. and Bertini, E. and Keim, D.},
	date = {2011-12},
	keywords = {{CloudLines}, computer displays, data analysis, data structures, data visualisation, Data visualization, decay function, Estimation, event based data, Event detection, event episode compact display, financial management, financial service, incremental data sets, Incremental visualization, information resources, interactive distortion, Internet, lens distortion., Lenses, logarithmic time scale, magnifying lens technique, multiple time series visualization technique, network security, online news streams, readability enhancement, security of data, temporal context, time-based representation, time series, Time series analysis},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/5Z6CQP5D/6065010.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IXHMFTJB/Krstajic 等. - 2011 - CloudLines Compact Display of Event Episodes in M.pdf:application/pdf}
}

@article{koch_iterative_2011,
	title = {Iterative Integration of Visual Insights during Scalable Patent Search and Analysis},
	volume = {17},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.85},
	abstract = {Patents are of growing importance in current economic markets. Analyzing patent information has, therefore, become a common task for many interest groups. As a prerequisite for patent analysis, extensive search for relevant patent information is essential. Unfortunately, the complexity of patent material inhibits a straightforward retrieval of all relevant patent documents and leads to iterative, time-consuming approaches in practice. Already the amount of patent data to be analyzed poses challenges with respect to scalability. Further scalability issues arise concerning the diversity of users and the large variety of analysis tasks. With "{PatViz}”, a system for interactive analysis of patent information has been developed addressing scalability at various levels. {PatViz} provides a visual environment allowing for interactive reintegration of insights into subsequent search iterations, thereby bridging the gap between search and analytic processes. Because of its extensibility, we expect that the approach we have taken can be employed in different problem domains that require high quality of search results regarding their completeness.},
	pages = {557--569},
	number = {5},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Koch, S. and Bosch, H. and Giereth, M. and Ertl, T.},
	date = {2011-05},
	keywords = {data analysis, data visualisation, Environmental economics, graphical user interfaces, Information analysis, information retrieval, information search and retrieval., Intellectual property, interactive analysis, interactive systems, iterative integration, iterative methods, patents, {PatViz}, Scalability, scalable patent search, Statistics, Visual analytics, Visual databases, visual insights, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7JNQQVH6/5482578.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/Q8J6QV2J/Koch 等. - 2011 - Iterative Integration of Visual Insights during Sc.pdf:application/pdf}
}

@article{cui_textflow:_2011,
	title = {{TextFlow}: Towards Better Understanding of Evolving Topics in Text},
	volume = {17},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2011.239},
	shorttitle = {{TextFlow}},
	abstract = {Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce {TextFlow}, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of {TextFlow} in helping users understand the major topic evolution patterns in time-varying text data.},
	pages = {2412--2421},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Cui, W. and Liu, S. and Tan, L. and Shi, C. and Song, Y. and Gao, Z. and Qu, H. and Tong, X.},
	date = {2011-12},
	keywords = {coherent visualization, convey complex relationships, critical event, Critical event., data mining, data visualisation, Data visualization, Feature extraction, Hierarchical Dirichlet process, Image color analysis, keyword correlation, Tag clouds, text analysis, {TextFlow}, Text visualization, three-level feature extraction, Topic evolution, topic evolution trend, topic mining model, topic mining technique, topics evolution, visualization technique},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PGNA5ZU9/6065008.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PTAJGWD6/Cui 等. - 2011 - TextFlow Towards Better Understanding of Evolving.pdf:application/pdf}
}

@article{lee_sparkclouds:_2010,
	title = {{SparkClouds}: Visualizing Trends in Tag Clouds},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.194},
	shorttitle = {{SparkClouds}},
	abstract = {Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce {SparkClouds}, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares {SparkClouds} with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that {SparkClouds}' ability to show trends compares favourably to the alternative visualizations.},
	pages = {1182--1189},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Lee, B. and Riche, N. H. and Karlson, A. K. and Carpendale, S.},
	date = {2010-11},
	keywords = {Clouds, Color, data visualisation, Data visualization, Encoding, evaluation, Internet, Layout, multiple line graphs, {SparkClouds}, stacked bar charts, Tag clouds, tag frequency, trend visualization, Visualization, World Wide Web},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/V3KQKM3X/5613457.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6I24GBAS/Lee 等. - 2010 - SparkClouds Visualizing Trends in Tag Clouds.pdf:application/pdf}
}

@article{dork_visual_2010,
	title = {A Visual Backchannel for Large-Scale Events},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.129},
	abstract = {We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.},
	pages = {1129--1138},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Dörk, M. and Gruen, D. and Williamson, C. and Carpendale, S.},
	date = {2010-11},
	keywords = {backchannel, Context, cross-filtering, data visualisation, Data visualization, digital backchannel, events, Graph Visualization, image cloud encoding, information filtering, information retrieval, information stream visualization, information visualization, interactive systems, interactive visual overview, large-scale event, microblogging, microblogging community, multifaceted visual overview, multiple views, natural disaster, online conversation, People Spiral, political speech, Real time systems, Shape, social networking (online), sport competition, Streaming media, Topic Streams, Twitter, visual backchannel, Visualization, visual saliency, Web-based coordinated-view system, World Wide Web},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/3RS8NMZ5/5613451.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4KZDGEMI/Dörk 等. - 2010 - A Visual Backchannel for Large-Scale Events.pdf:application/pdf}
}

@article{cao_facetatlas:_2010,
	title = {{FacetAtlas}: Multifaceted Visualization for Rich Text Corpora},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.154},
	shorttitle = {{FacetAtlas}},
	abstract = {Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present {FacetAtlas}, a multifaceted visualization technique for visually analyzing rich text corpora. {FacetAtlas} combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of {FacetAtlas}, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of {FacetAtlas} through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.},
	pages = {1172--1181},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Cao, N. and Sun, J. and Lin, Y. R. and Gotz, D. and Liu, S. and Qu, H.},
	date = {2010-11},
	keywords = {automated opacity pattern enhancement, Cluster Analysis, complex multifaceted data analysis, Computer Graphics, Context, data analysis, data mining, Data models, data visualisation, Data visualization, Diabetes, Diabetes Mellitus, Diagnosis, Computer-Assisted, Diseases, document clusters, {FacetAtlas}, health care domain, {HIV} Infections, Humans, multifaceted edges, multifaceted relations, Multifaceted visualization, multifaceted visualization technique, multiple facets, Multi-relational Graph, node cliques, optimized density map, patient education, pattern clustering, Pattern Recognition, Automated, rich text corpora, search problems, search technology, search tools, Search {UI}, Switches, text analysis, Text visualization, visual analytical tools, Visualization, visual patterns},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/JVA63INU/5613456.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/9S7W75NF/Cao 等. - 2010 - FacetAtlas Multifaceted Visualization for Rich Te.pdf:application/pdf}
}

@article{wu_opinionseer:_2010,
	title = {{OpinionSeer}: Interactive Visualization of Hotel Customer Feedback},
	volume = {16},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2010.183},
	shorttitle = {{OpinionSeer}},
	abstract = {The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present {OpinionSeer}, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of {OpinionSeer} on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, {OpinionSeer} could also be applied to visually analyze customer opinions on other products or services.},
	pages = {1109--1118},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Wu, Y. and Wei, F. and Liu, S. and Au, N. and Cui, W. and Zhou, H. and Qu, H.},
	date = {2010-11},
	keywords = {data mining, data visualisation, Data visualization, Feature extraction, feedback, hotel customer feedback, hotel industry, hotel services, interactive systems, interactive visualization system, Internet, Layout, online customer opinions, {OpinionSeer}, opinion visualization, radial visualization, scatterplots, subjective logic, Uncertainty, uncertainty visualization, visual analysis, Visualization, visualization-centric opinion mining technique, Web technology, Wheels},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/R6M6KFUV/5613449.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/VM3J8QEM/Wu 等. - 2010 - OpinionSeer Interactive Visualization of Hotel Cu.pdf:application/pdf}
}

@article{collins_bubble_2009,
	title = {Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.122},
	shorttitle = {Bubble Sets},
	abstract = {While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.},
	pages = {1009--1016},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Collins, C. and Penn, G. and Carpendale, S.},
	date = {2009-11},
	keywords = {Air conditioning, Bubble sets, clustering, Cognitive science, data relationship, data sets, data visualisation, Data visualization, Graph Visualization, isocontours, primary data relation, Scattering, set cluster continuity, set relation, set theory, Social network services, spatial layout, Tree graphs, tree visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GPXQHZHW/5290706.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/QXPA588A/Collins 等. - 2009 - Bubble Sets Revealing Set Relations with Isoconto.pdf:application/pdf}
}

@article{viegas_participatory_2009,
	title = {Participatory Visualization with Wordle},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.171},
	abstract = {We discuss the design and usage of {ldquoWordle},rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.},
	pages = {1137--1144},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Viegas, F. B. and Wattenberg, M. and Feinberg, J.},
	date = {2009-11},
	keywords = {data analysis, data visualisation, educational visualization, Memory, participatory culture, social data analysis, tag cloud, tag-cloud-like displays, text, text analysis, text visualisation, Visualization, Web-based tool, Web sites, Wordle, Wordle layouts},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H27PJSKD/5290722.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/VEDETRWS/Viegas 等. - 2009 - Participatory Visualization with Wordle.pdf:application/pdf}
}

@article{ham_mapping_2009,
	title = {Mapping Text with Phrase Nets},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.165},
	abstract = {We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.},
	pages = {1169--1176},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Ham, F. van and Wattenberg, M. and Viegas, F. B.},
	date = {2009-11},
	keywords = {Books, Computer network reliability, data visualisation, Displays, Natural Language Processing, Pattern analysis, Pattern matching, phrase nets, semantic net, Speech, tag cloud, Tag clouds, text analysis, text mapping, Text visualization, Turning, user-specified relation, Visualization, visual overviews},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/J92BHNHG/5290726.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/3TV6J5TH/Ham 等. - 2009 - Mapping Text with Phrase Nets.pdf:application/pdf}
}

@article{strobelt_document_2009,
	title = {Document Cards: A Top Trumps Visualization for Documents},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.139},
	shorttitle = {Document Cards},
	abstract = {Finding suitable, less space consuming views for a document's main content is crucial to provide convenient access to large document collections on display devices of different size. We present a novel compact visualization which represents the document's key semantic as a mixture of images and important key terms, similar to cards in a top trumps game. The key terms are extracted using an advanced text mining approach based on a fully automatic document structure extraction. The images and their captions are extracted using a graphical heuristic and the captions are used for a semi-semantic image weighting. Furthermore, we use the image color histogram for classification and show at least one representative from each non-empty image class. The approach is demonstrated for the {IEEE} {InfoVis} publications of a complete year. The method can easily be applied to other publication collections and sets of documents which contain images.},
	pages = {1145--1152},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Strobelt, H. and Oelke, D. and Rohrdantz, C. and Stoffel, A. and Keim, D. A. and Deussen, O.},
	date = {2009-11},
	keywords = {advanced text mining, compact visualization, content extraction, data mining, data visualisation, display devices, Displays, document cards, document collection browsing, document image processing, document structure extraction, document visualization, Feeds, Histograms, {IEEE} {InfoVis} publications, image color histogram, Image databases, Operating systems, Pipelines, search engines, semi-semantic image weighting, Text mining, top trumps document visualization, Visualization, visual summary},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/HIR9VT7E/5290723.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/7EEXA2QA/Strobelt 等. - 2009 - Document Cards A Top Trumps Visualization for Doc.pdf:application/pdf}
}

@article{chen_exemplar-based_2009,
	title = {Exemplar-based Visualization of Large Document Corpus ({InfoVis}2009-1115)},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.140},
	abstract = {With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization ({EV}), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, {EV} presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of {EV} through extensive experiments performed on the publicly available text data sets.},
	pages = {1161--1168},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Chen, Y. and Wang, L. and Dong, M. and Hua, J.},
	date = {2009-11},
	keywords = {biology computing, Computer science, data visualisation, Data visualization, Drugs, Exemplar, exemplar-based visualization, Indexing, iterative methods, iterative optimization, large document corpus, large-scale document visualization, Large-scale systems, matrix approximation, matrix decomposition, multidimensional projection., Multidimensional systems, optimisation, parameter embedding, Principal component analysis, text corpus, Text mining, Text visualization, Web sites},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CPUP3ESP/5290725.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PNRJI9HB/Chen 等. - 2009 - Exemplar-based Visualization of Large Document Cor.pdf:application/pdf}
}

@article{paulovich_hipp:_2008,
	title = {{HiPP}: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections},
	volume = {14},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.138},
	shorttitle = {{HiPP}},
	abstract = {Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.},
	pages = {1229--1236},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Paulovich, F. V. and Minghim, R.},
	date = {2008-11},
	keywords = {analysis capability, Computational efficiency, data mining, Data visualization, Displays, document collections, Document handling, hierarchical multidimensional visualization, hierarchical point placement strategy, high-dimensional data., {HiPP}, Index Terms—Text and document visualization, Multidimensional systems, text analysis, visual knowledge discovery},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FC649NJG/4658134.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/XE8MMEE5/Paulovich 和 Minghim - 2008 - HiPP A Novel Hierarchical Point Placement Strateg.pdf:application/pdf}
}

@article{wattenberg_word_2008,
	title = {The Word Tree, an Interactive Visual Concordance},
	volume = {14},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2008.172},
	abstract = {We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional "keyword-in-context" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.},
	pages = {1221--1228},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Wattenberg, M. and Viégas, F. B.},
	date = {2008-11},
	keywords = {Blogs, case study, computer displays, concordance, data visualisation, Data visualization, Document handling, document visualization, Drilling, Eyes, feedback, Frequency, Index Terms—Many Eyes, information retrieval, information-retrieval technique, interactive visual concordance, keyword-in-context method, Many Eyes, search., Text visualization, tree data structures, Tree graphs, word tree},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/ENZFBBBT/4658133.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6SHGBZME/Wattenberg 和 Viégas - 2008 - The Word Tree, an Interactive Visual Concordance.pdf:application/pdf}
}

@article{lee_sketchstory:_2013,
	title = {{SketchStory}: Telling More Engaging Stories with Data through Freeform Sketching},
	volume = {19},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2013.191},
	shorttitle = {{SketchStory}},
	abstract = {Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present {SketchStory}, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. {SketchStory} recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, {SketchStory} allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare {SketchStory} with a traditional presentation system, Microsoft {PowerPoint}. Results show that the audience is more engaged by presentations done with {SketchStory} than {PowerPoint}. Eighteen out of 24 audience participants preferred {SketchStory} to {PowerPoint}. Four out of five presenter participants also favored {SketchStory} despite the extra effort required for presentation.},
	pages = {2416--2425},
	number = {12},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Lee, B. and Kazi, R. H. and Smith, G.},
	date = {2013-12},
	keywords = {Algorithms, Animation, computer animation, Computer Graphics, data charts, data-enabled digital whiteboard, data exploration, data presentation, data visualisation, Data visualization, Filtering, freeform sketching, gesture recognition, Image Enhancement, Information Dissemination, information visualization, Interaction, Microsoft {PowerPoint}, Narration, narrative storytelling attributes, Paintings, pen and touch, pen-and-touch interactions, presenter-provided example icon, Real-time systems, Rendering (computer graphics), sketch, sketch gestures, {SketchStory}, storytelling, User-Computer Interface, Visualization, whiteboard animation},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/W9G4MPE3/6634113.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/BI4FPZJ6/Lee 等. - 2013 - SketchStory Telling More Engaging Stories with Da.pdf:application/pdf}
}

@article{alexander_task-driven_2016,
	title = {Task-Driven Comparison of Topic Models},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2467618},
	abstract = {Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.},
	pages = {320--329},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Alexander, E. and Gleicher, M.},
	date = {2016-01},
	keywords = {Analytical models, buddy plots, Color, color encodings, Computational modeling, data visualisation, document similarity, Encoding, large text collection, Measurement, numerical metrics, Numerical models, position encodings, task-centric topic model comparison, text analysis, Text visualization, thematic content extraction, topic modeling, understanding change, understanding similarity, understanding topics, Visualization, visualization techniques},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/R6QEAVNM/7194832.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4N7AE5Q4/Alexander 和 Gleicher - 2016 - Task-Driven Comparison of Topic Models.pdf:application/pdf}
}

@article{itti_computational_2001,
	title = {Computational modelling of visual attention},
	volume = {2},
	rights = {© 2001 Nature Publishing Group},
	issn = {1471-003X},
	url = {http://www.nature.com/nrn/journal/v2/n3/abs/nrn0301_194a.html},
	doi = {10.1038/35058500},
	abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
	pages = {194--203},
	number = {3},
	journaltitle = {Nature Reviews Neuroscience},
	shortjournal = {Nat Rev Neurosci},
	author = {Itti, Laurent and Koch, Christof},
	urldate = {2017-02-05},
	date = {2001-03},
	langid = {english},
	file = {Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2INAP2CG/nrn0301_194a.html:text/html}
}

@article{walther_modeling_2006,
	title = {Modeling attention to salient proto-objects},
	volume = {19},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608006002152},
	doi = {10.1016/j.neunet.2006.10.001},
	series = {Brain and {AttentionBrain} and Attention},
	abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
	pages = {1395--1407},
	number = {9},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Walther, Dirk and Koch, Christof},
	urldate = {2017-02-05},
	date = {2006-11},
	keywords = {Attention model, Object recognition, Proto-objects, visual attention},
	file = {ScienceDirect Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/2TKBZ3HU/Walther 和 Koch - 2006 - Modeling attention to salient proto-objects.pdf:application/pdf;ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FEXJX7ZX/S0893608006002152.html:text/html}
}

@article{itti_model_1998,
	title = {A model of saliency-based visual attention for rapid scene analysis},
	volume = {20},
	issn = {0162-8828},
	doi = {10.1109/34.730558},
	abstract = {A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail},
	pages = {1254--1259},
	number = {11},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Itti, L. and Koch, C. and Niebur, E.},
	date = {1998-11},
	keywords = {Biological system modeling, Brain modeling, Computer architecture, computer vision, dynamical neural network, Feature extraction, Hardware, Image analysis, image recognition, Layout, neural nets, Neural networks, Object detection, rapid scene analysis, saliency, scene understanding, target detection, Target tracking, topographical saliency map, visual attention, visual search, Visual system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/M3T26GMD/730558.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IIST39BC/Itti 等. - 1998 - A model of saliency-based visual attention for rap.pdf:application/pdf}
}

@article{petersen_attention_2012,
	title = {The Attention System of the Human Brain: 20 Years After},
	volume = {35},
	issn = {0147-006X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3413263/},
	doi = {10.1146/annurev-neuro-062111-150525},
	shorttitle = {The Attention System of the Human Brain},
	abstract = {Here, we update our 1990 Annual Review of Neuroscience article, “The Attention System of the Human Brain.” The framework presented in the original article has helped to integrate behavioral, systems, cellular, and molecular approaches to common problems in attention research. Our framework has been both elaborated and expanded in subsequent years. Research on orienting and executive functions has supported the addition of new networks of brain regions. Developmental studies have shown important changes in control systems between infancy and childhood. In some cases, evidence has supported the role of specific genetic variations, often in conjunction with experience, that account for some of the individual differences in the efficiency of attentional networks. The findings have led to increased understanding of aspects of pathology and to some new interventions.},
	pages = {73--89},
	journaltitle = {Annual review of neuroscience},
	shortjournal = {Annu Rev Neurosci},
	author = {Petersen, Steven E. and Posner, Michael I.},
	urldate = {2017-02-06},
	date = {2012-07-21},
	pmid = {22524787},
	pmcid = {PMC3413263},
	file = {PubMed Central Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/DACDKU8B/Petersen 和 Posner - 2012 - The Attention System of the Human Brain 20 Years .pdf:application/pdf}
}

@article{itti_models_????,
	title = {Models of Bottom-Up Attention and Saliency},
	url = {http://s3.amazonaws.com/academia.edu.documents/30739887/10.1.1.76.9678.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1486353112&Signature=gcrhG89T9As1%2FTquEQ0ZTCythGE%3D&response-content-disposition=inline%3B%20filename%3DModels_of_bottom-up_attention_and_salien.pdf},
	author = {Itti, Laurent},
	urldate = {2017-02-06},
	file = {10.1.1.76.9678.pdf:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/PUDXAP4V/10.1.1.76.9678.pdf:application/pdf}
}

@book{munzner_visualization_2014-1,
	title = {Visualization Analysis and Design},
	isbn = {978-1-4665-0893-4},
	abstract = {Learn How to Design Effective Visualization Systems Visualization Analysis and Design provides a systematic, comprehensive framework for thinking about visualization in terms of principles and design choices. The book features a unified approach encompassing information visualization techniques for abstract data, scientific visualization techniques for spatial data, and visual analytics techniques for interweaving data transformation and analysis with interactive visual exploration. It emphasizes the careful validation of effectiveness and the consideration of function before form.   The book breaks down visualization design according to three questions: what data users need to see, why users need to carry out their tasks, and how the visual representations proposed can be constructed and manipulated. It walks readers through the use of space and color to visually encode data in a view, the trade-offs between changing a single view and using multiple linked views, and the ways to reduce the amount of data shown in each view. The book concludes with six case studies analyzed in detail with the full framework.  The book is suitable for a broad set of readers, from beginners to more experienced visualization designers. It does not assume any previous experience in programming, mathematics, human–computer interaction, or graphic design and can be used in an introductory visualization course at the graduate or undergraduate level.},
	pagetotal = {422},
	publisher = {{CRC} Press},
	author = {Munzner, Tamara},
	date = {2014-12-01},
	langid = {english},
	note = {Google-Books-{ID}: {dznSBQAAQBAJ}},
	keywords = {Business \& Economics / Statistics, Computers / Computer Graphics, Computers / Databases / General, Computers / General, Computers / Social Aspects / Human-Computer Interaction, Technology \& Engineering / Industrial Health \& Safety}
}

@article{itti_saliency-based_2000,
	title = {A saliency-based search mechanism for overt and covert shifts of visual attention},
	volume = {40},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698999001637},
	doi = {10.1016/S0042-6989(99)00163-7},
	abstract = {Most models of visual search, whether involving overt eye movements or covert shifts of attention, are based on the concept of a saliency map, that is, an explicit two-dimensional map that encodes the saliency or conspicuity of objects in the visual environment. Competition among neurons in this map gives rise to a single winning location that corresponds to the next attended target. Inhibiting this location automatically allows the system to attend to the next most salient location. We describe a detailed computer implementation of such a scheme, focusing on the problem of combining information across modalities, here orientation, intensity and color information, in a purely stimulus-driven manner. The model is applied to common psychophysical stimuli as well as to a very demanding visual search task. Its successful performance is used to address the extent to which the primate visual system carries out visual search via one or more such saliency maps and how this can be tested.},
	pages = {1489--1506},
	number = {10},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Itti, Laurent and Koch, Christof},
	urldate = {2017-02-06},
	date = {2000-06},
	keywords = {saliency, Vision systems, visual attention},
	file = {ScienceDirect Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/37F8X2U4/Itti 和 Koch - 2000 - A saliency-based search mechanism for overt and co.pdf:application/pdf;ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/JGP6QZ3J/S0042698999001637.html:text/html}
}

@article{satyanarayan_vega-lite:_2017,
	title = {Vega-Lite: A Grammar of Interactive Graphics},
	volume = {23},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2016.2599030},
	shorttitle = {Vega-Lite},
	abstract = {We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.},
	pages = {341--350},
	number = {1},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Satyanarayan, A. and Moritz, D. and Wongsuphasawat, K. and Heer, J.},
	date = {2017-01},
	keywords = {Brushes, composition algebra, conditional logic, customized interaction methods, data visualisation, Data visualization, declarative specification, Encoding, Grammar, grammars, high-level grammar, inclusion testing, information visualization, Interaction, interactive data visualizations, interactive graphics, interactive systems, linked selection, multiview displays, program compilers, systems, toolkits, Transforms, Vega-Lite compiler, visual encoding rules, visual encodings, Visualization},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/VA8N4XJX/7539624.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/99KHKM7J/Satyanarayan 等. - 2017 - Vega-Lite A Grammar of Interactive Graphics.pdf:application/pdf}
}

@inproceedings{callahan_vistrails:_2006,
	location = {New York, {NY}, {USA}},
	title = {{VisTrails}: Visualization Meets Data Management},
	isbn = {978-1-59593-434-5},
	url = {http://doi.acm.org/10.1145/1142473.1142574},
	doi = {10.1145/1142473.1142574},
	series = {{SIGMOD} '06},
	shorttitle = {{VisTrails}},
	abstract = {Scientists are now faced with an incredible volume of data to analyze. To successfully analyze and validate various hypothesis, it is necessary to pose several queries, correlate disparate data, and create insightful visualizations of both the simulated processes and observed phenomena. Often, insight comes from comparing the results of multiple visualizations. Unfortunately, today this process is far from interactive and contains many error-prone and time-consuming tasks. As a result, the generation and maintenance of visualizations is a major bottleneck in the scientific process, hindering both the ability to mine scientific data and the actual use of the data. The {VisTrails} system represents our initial attempt to improve the scientific discovery process and reduce the time to insight. In {VisTrails}, we address the problem of visualization from a data management perspective: {VisTrails} manages the data and metadata of a visualization product. In this demonstration, we show the power and flexibility of our system by presenting actual scenarios in which scientific visualization is used and showing how our system improves usability, enables reproducibility, and greatly reduces the time required to create scientific visualizations.},
	pages = {745--747},
	booktitle = {Proceedings of the 2006 {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {{ACM}},
	author = {Callahan, Steven P. and Freire, Juliana and Santos, Emanuele and Scheidegger, Carlos E. and Silva, Cláudio T. and Vo, Huy T.},
	urldate = {2017-02-09},
	date = {2006},
	keywords = {data provenance, scientific dataflows, Visualization},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WIEP55QN/Callahan 等. - 2006 - VisTrails Visualization Meets Data Management.pdf:application/pdf}
}

@article{heer_animated_2007-1,
	title = {Animated Transitions in Statistical Data Graphics},
	volume = {13},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2007.70539},
	abstract = {In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in {DynaVis}, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.},
	pages = {1240--1247},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Heer, J. and Robertson, G.},
	date = {2007-11},
	keywords = {animated transitions, Animation, bar charts, Collaboration, computer animation, data visualisation, Data visualization, design, Drilling, {DynaVis}, experiment, graphical perception, Graphics, Guidelines, Information analysis, information visualization, Marketing and sales, pie charts, Scattering, scatter plots, statistical analysis, statistical data graphics, Taxonomy, transitions, visualization system},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CJ2WNHS2/4376146.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/6RJPF67W/Heer 和 Robertson - 2007 - Animated Transitions in Statistical Data Graphics.pdf:application/pdf}
}

@inproceedings{wang_animated_2016,
	location = {New York, {NY}, {USA}},
	title = {Animated Narrative Visualization for Video Clickstream Data},
	isbn = {978-1-4503-4547-7},
	url = {http://doi.acm.org/10.1145/3002151.3002155},
	doi = {10.1145/3002151.3002155},
	series = {{SA} '16},
	abstract = {Video clickstream data are important for understanding user behaviors and improving online video services. Various visual analytics techniques have been proposed to explore patterns in these data. However, those techniques are mainly developed for analysis and do not sufficiently support presentations. It is still difficult for data analysts to convey their findings to an audience without prior knowledge. In this paper, we propose to use animated narrative visualization to present video clickstream data. Compared with traditional methods which directly turn click events into animations, our animated narrative visualization focuses on conveying the patterns in the data to a general audience and adopts two novel designs, non-linear time mapping and foreshadowing, to make the presentation more engaging and interesting. Our non-linear time mapping method keeps the interesting parts as the focus of the animation while compressing the uninteresting parts as the context. The foreshadowing techniques can engage the audience and alert them to the events in the animation. Our user study indicates the effectiveness of our system and provides guidelines for the design of similar systems.},
	pages = {11:1--11:8},
	booktitle = {{SIGGRAPH} {ASIA} 2016 Symposium on Visualization},
	publisher = {{ACM}},
	author = {Wang, Yun and Chen, Zhutian and Li, Quan and Ma, Xiaojuan and Luo, Qiong and Qu, Huamin},
	urldate = {2017-02-20},
	date = {2016},
	keywords = {animated visualization, clickstream data, data storytelling, Narrative visualization},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WMW786DZ/Wang 等. - 2016 - Animated Narrative Visualization for Video Clickst.pdf:application/pdf}
}

@article{ruchikachorn_learning_2015,
	title = {Learning Visualizations by Analogy: Promoting Visual Literacy through Visualization Morphing},
	volume = {21},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2413786},
	shorttitle = {Learning Visualizations by Analogy},
	abstract = {We propose the concept of teaching (and learning) unfamiliar visualizations by analogy, that is, demonstrating an unfamiliar visualization method by linking it to another more familiar one, where the in-betweens are designed to bridge the gap of these two visualizations and explain the difference in a gradual manner. As opposed to a textual description, our morphing explains an unfamiliar visualization through purely visual means. We demonstrate our idea by ways of four visualization pair examples: data table and parallel coordinates, scatterplot matrix and hyperbox, linear chart and spiral chart, and hierarchical pie chart and treemap. The analogy is commutative i.e. any member of the pair can be the unfamiliar visualization. A series of studies showed that this new paradigm can be an effective teaching tool. The participants could understand the unfamiliar visualization methods in all of the four pairs either fully or at least significantly better after they observed or interacted with the transitions from the familiar counterpart. The four examples suggest how helpful visualization pairings be identified and they will hopefully inspire other visualization morphings and associated transition strategies to be identified.},
	pages = {1028--1044},
	number = {9},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Ruchikachorn, P. and Mueller, K.},
	date = {2015-09},
	keywords = {Animation, associated transition strategy, computer literacy, computer science education, data table, data visualisation, Data visualization, Education, hierarchical pie chart, hyperbox, information visualization, Interaction, Joining processes, Layout, linear chart, Literacy, Multivariate Visualization, parallel coordinates, scatterplot matrix, spiral chart, Spirals, teaching, textual description, treemap, unfamiliar visualization teaching method, Visualization, visualization by analogy learning, visualization morphing, visual literacy},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/99TX3NQB/7061477.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/557U9WKG/Ruchikachorn 和 Mueller - 2015 - Learning Visualizations by Analogy Promoting Visu.pdf:application/pdf}
}

@article{standage_modelling_2005,
	title = {Modelling divided visual attention with a winner-take-all network},
	volume = {18},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/S089360800500122X},
	doi = {10.1016/j.neunet.2005.06.015},
	series = {{IJCNN} 2005},
	abstract = {Experimental evidence on the distribution of visual attention supports the idea of a spatial saliency map, whereby bottom-up and top-down influences on attention are integrated by a winner-take-all mechanism. We implement this map with a continuous attractor neural network, and test the ability of our model to explain experimental evidence on the distribution of spatial attention. The majority of evidence supports the view that attention is unitary, but recent experiments provide evidence for split attentional foci. We simulate two such experiments. Our results suggest that the ability to divide attention depends on sustained endogenous signals from short term memory to the saliency map, stressing the interplay between working memory mechanisms and attention.},
	pages = {620--627},
	number = {5},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Standage, Dominic I. and Trappenberg, Thomas P. and Klein, Raymond M.},
	urldate = {2017-03-02},
	date = {2005-07},
	keywords = {Spatial saliency, visual attention, Winner-take-all},
	file = {ScienceDirect Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/H4MAA9SZ/Standage 等. - 2005 - Modelling divided visual attention with a winner-t.pdf:application/pdf;ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/EW9U55HH/S089360800500122X.html:text/html}
}

@article{treisman_feature_1998,
	title = {Feature binding, attention and object perception.},
	volume = {353},
	issn = {0962-8436},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1692340/},
	abstract = {The seemingly effortless ability to perceive meaningful objects in an integrated scene actually depends on complex visual processes. The 'binding problem' concerns the way in which we select and integrate the separate features of objects in the correct combinations. Experiments suggest that attention plays a central role in solving this problem. Some neurological patients show a dramatic breakdown in the ability to see several objects; their deficits suggest a role for the parietal cortex in the binding process. However, indirect measures of priming and interference suggest that more information may be implicitly available than we can consciously access.},
	pages = {1295--1306},
	number = {1373},
	journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	shortjournal = {Philos Trans R Soc Lond B Biol Sci},
	author = {Treisman, A},
	urldate = {2017-03-02},
	date = {1998-08-29},
	pmid = {9770223},
	pmcid = {PMC1692340},
	file = {PubMed Central Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4DJ7K2IN/Treisman - 1998 - Feature binding, attention and object perception..pdf:application/pdf}
}

@article{chen_peakvizor:_2016,
	title = {{PeakVizor}: Visual Analytics of Peaks in Video Clickstreams from Massive Open Online Courses},
	volume = {22},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2015.2505305},
	shorttitle = {{PeakVizor}},
	abstract = {Massive open online courses ({MOOCs}) aim to facilitate open-access and massive-participation education. These courses have attracted millions of learners recently. At present, most {MOOC} platforms record the Web log data of learner interactions with course videos. Such large amounts of multivariate data pose a new challenge in terms of analyzing online learning behaviors. Previous studies have mainly focused on the aggregate behaviors of learners from a summative view; however, few attempts have been made to conduct a detailed analysis of such behaviors. To determine complex learning patterns in {MOOC} video interactions, this paper introduces a comprehensive visualization system called {PeakVizor}. This system enables course instructors and education experts to analyze the “peaks” or the video segments that generate numerous clickstreams. The system features three views at different levels: the overview with glyphs to display valuable statistics regarding the peaks detected; the flow view to present spatio-temporal information regarding the peaks; and the correlation view to show the correlation between different learner groups and the peaks. Case studies and interviews conducted with domain experts have demonstrated the usefulness and effectiveness of {PeakVizor}, and new findings about learning behaviors in {MOOC} platforms have been reported.},
	pages = {2315--2330},
	number = {10},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Chen, Q. and Chen, Y. and Liu, D. and Shi, C. and Wu, Y. and Qu, H.},
	date = {2016-10},
	keywords = {Aggregates, behavioural sciences computing, clickstream data, complex learning patterns, comprehensive visualization system, Correlation, correlation view, course videos, courseware, Data visualization, educational courses, Electronic learning, glyphs, interactive video, learner groups, learner interactions, massive open online courses, {MOOC}, {MOOC} video interactions, multivariate data, online education, online learning behavior analysis, open-access massive-participation education, {PeakVizor}, spatio-temporal information, video clickstreams peaks, Visual analytics, Web log data recording},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CFDZ6KJP/7346501.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/F25WRK3M/Chen 等. - 2016 - PeakVizor Visual Analytics of Peaks in Video Clic.pdf:application/pdf}
}

@article{dong_why_2014,
	title = {Why the processing of repeated targets are better than that of no repetition: evidence from easy-to-difficult and difficult-to-easy switching situations},
	volume = {10},
	issn = {1744-9081},
	url = {http://dx.doi.org/10.1186/1744-9081-10-4},
	doi = {10.1186/1744-9081-10-4},
	shorttitle = {Why the processing of repeated targets are better than that of no repetition},
	abstract = {Previous studies have found that the processing of repeated targets are easier than that of non-repetition. Although several theories attempt to explain this issue, the underlying mechanism still remains uncovered. In this study, we tried to address this issue by exploring the underlying brain responses during this process.},
	pages = {4},
	journaltitle = {Behavioral and Brain Functions},
	shortjournal = {Behavioral and Brain Functions},
	author = {Dong, Guangheng and Zhou, Hongli and Lin, Xiao and Hu, Yanbo and Lu, Qilin},
	urldate = {2017-03-02},
	date = {2014},
	keywords = {Priming effect, Repeating situation, Switch cost, Switching situation},
	file = {Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/EV866GDJ/Dong 等. - 2014 - Why the processing of repeated targets are better .pdf:application/pdf;Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RQIV9JHW/1744-9081-10-4.html:text/html}
}

@report{bliss_effects_1992,
	title = {The Effects of Easy-To-Difficult, Difficult-Only, and Mixed-Difficulty Practice on Performance of Simulated Gunnery Tasks},
	rights = {Approved for public release; distribution is unlimited.},
	author = {Bliss, James P. and Lampton, Donald R. and Boldovici, John A.},
	date = {1992-04},
	langid = {english},
	keywords = {*{GUNNERY}, *{PERFORMANCE}({HUMAN}), *{TRAINING} {DEVICES}, {AIMING}, {AS}795, {ERRORS}, Fire Control and Bombing Systems, {LEARNING}, {MEAN}, {MOVING} {TARGETS}, {PE}63007A, {STRATEGY}, {TARGETS}, {TEST} {AND} {EVALUATION}, {TIME}, Tracking, {TRAINING}},
	file = {DTIC Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/RT4ZWFAA/Bliss 等. - 1992 - The Effects of Easy-To-Difficult, Difficult-Only, .pdf:application/pdf;DTIC Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/FR2FIT3J/oai.html:text/html}
}

@article{nothdurft_salience_2000,
	title = {Salience from feature contrast: variations with texture density},
	volume = {40},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698900001681},
	doi = {10.1016/S0042-6989(00)00168-1},
	shorttitle = {Salience from feature contrast},
	abstract = {The salience of popout targets was measured in regular line arrays as a function of texture density. Test targets (singletons with orientation, motion, or luminance contrast) presented at different raster widths were compared with reference lines (lines brighter than surrounding lines) presented at fixed raster width. The luminance at which the reference target appeared as salient as the particular test target was taken as a measure of the relative salience of the test target. For orientation or motion contrast, targets at medium to small raster widths were far more salient than targets in sparse or very dense line arrangements. For targets defined by luminance contrast, salience variations with texture density were less pronounced. Some subjects also reported salience for lines in sparse arrangements even when these did not display feature contrast. When such non-specific saliency effects were subtracted from the actual measurements, salience curves for orientation or motion contrast revealed peaks of increased sensitivity at line spacings below 2–3 deg and flat curves at larger grid sizes. In an additional experiment, saliency effects from orientation contrast were measured using texture lines of different size. Salience variations were commonly observed. However, the curves were not found to scale with the different sizes of texture elements but were constantly related to the free space between neighbouring lines. This suggests that peaks in the salience profiles reflect the limited spatial extent of the underlying neural mechanisms.},
	pages = {3181--3200},
	number = {23},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Nothdurft, Hans-Christoph},
	urldate = {2017-03-02},
	date = {2000-01},
	keywords = {Contextual modulation, Local mechanism, Luminance contrast, Motion contrast, Orientation contrast, Popout, Psychophysics, Salience},
	file = {ScienceDirect Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/4EAQ64DG/Nothdurft - 2000 - Salience from feature contrast variations with te.pdf:application/pdf;ScienceDirect Snapshot:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/GVEJEMP7/S0042698900001681.html:text/html}
}

@inproceedings{mendez_ivolver:_2016,
	location = {New York, {NY}, {USA}},
	title = {{iVoLVER}: Interactive Visual Language for Visualization Extraction and Reconstruction},
	isbn = {978-1-4503-3362-7},
	url = {http://doi.acm.org/10.1145/2858036.2858435},
	doi = {10.1145/2858036.2858435},
	series = {{CHI} '16},
	shorttitle = {{iVoLVER}},
	abstract = {We present the design and implementation of {iVoLVER}, a tool that allows users to create visualizations without textual programming. {iVoLVER} is designed to enable flexible acquisition of many types of data (text, colors, shapes, quantities, dates) from multiple source types (bitmap charts, webpages, photographs, {SVGs}, {CSV} files) and, within the same canvas, supports transformation of that data through simple widgets to construct interactive animated visuals. Aside from the tool, which is web-based and designed for pen and touch, we contribute the design of the interactive visual language and widgets for extraction, transformation, and representation of data. We demonstrate the flexibility and expressive power of the tool through a set of scenarios, and discuss some of the challenges encountered and how the tool fits within the current infovis tool landscape.},
	pages = {4073--4085},
	booktitle = {Proceedings of the 2016 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Méndez, Gonzalo Gabriel and Nacenta, Miguel A. and Vandenheste, Sebastien},
	urldate = {2017-03-03},
	date = {2016},
	keywords = {information visualization, visual information extraction, visualization verification, visual languages for visualization},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/CRP6S4R4/Méndez 等. - 2016 - iVoLVER Interactive Visual Language for Visualiza.pdf:application/pdf}
}

@article{bostock_protovis:_2009,
	title = {Protovis: A Graphical Toolkit for Visualization},
	volume = {15},
	issn = {1077-2626},
	doi = {10.1109/TVCG.2009.174},
	shorttitle = {Protovis},
	abstract = {Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering {APIs} and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency - the effort required to specify a visualization - and accessibility - the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools.},
	pages = {1121--1128},
	number = {6},
	journaltitle = {{IEEE} Transactions on Visualization and Computer Graphics},
	author = {Bostock, M. and Heer, J.},
	date = {2009-11},
	keywords = {2D graphics., application program interfaces, Computer science, Costs, Data processing, data visualisation, Data visualization, Domain specific languages, Encoding, graphical visualization toolkit, Graphics, high-level visualization systems, information visualization, low-level graphical systems, Protovis, rendering {API}, Rendering (computer graphics), Software tools, toolkits, user interfaces, vector-based drawing programs},
	file = {IEEE Xplore Abstract Record:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/JQSQI9NF/5290720.html:text/html;IEEE Xplore Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/Q86JUTJQ/Bostock 和 Heer - 2009 - Protovis A Graphical Toolkit for Visualization.pdf:application/pdf}
}

@inproceedings{huron_constructive_2014,
	location = {New York, {NY}, {USA}},
	title = {Constructive Visualization},
	isbn = {978-1-4503-2902-6},
	url = {http://doi.acm.org/10.1145/2598510.2598566},
	doi = {10.1145/2598510.2598566},
	series = {{DIS} '14},
	abstract = {If visualization is to be democratized, we need to provide means for non-experts to create visualizations that allow them to engage directly with datasets. We present constructive visualization a new paradigm for the simple creation of flexible, dynamic visualizations. Constructive visualization is simple-in that the skills required to build and manipulate the visualizations are akin to kindergarten play; it is expressive in that one can build within the constraints of the chosen environment, and it also supports dynamics -- in that these constructed visualizations can be rebuilt and adjusted. We de- scribe the conceptual components and processes underlying constructive visualization, and present real-world examples to illustrate the utility of this approach. The constructive visualization approach builds on our inherent understanding and experience with physical building blocks, offering a model that enables non-experts to create entirely novel visualizations, and to engage with datasets in a manner that would not have otherwise been possible.},
	pages = {433--442},
	booktitle = {Proceedings of the 2014 Conference on Designing Interactive Systems},
	publisher = {{ACM}},
	author = {Huron, Samuel and Carpendale, Sheelagh and Thudt, Alice and Tang, Anthony and Mauerer, Michael},
	urldate = {2017-03-07},
	date = {2014},
	keywords = {assembling, construction, constructionism, constructivism, design, Education, Visualization, visual literacy.},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/IGHTMNH5/Huron 等. - 2014 - Constructive Visualization.pdf:application/pdf}
}

@inproceedings{savva_revision:_2011,
	location = {New York, {NY}, {USA}},
	title = {{ReVision}: Automated Classification, Analysis and Redesign of Chart Images},
	isbn = {978-1-4503-0716-1},
	url = {http://doi.acm.org/10.1145/2047196.2047247},
	doi = {10.1145/2047196.2047247},
	series = {{UIST} '11},
	shorttitle = {{ReVision}},
	abstract = {Poorly designed charts are prevalent in reports, magazines, books and on the Web. Most of these charts are only available as bitmap images; without access to the underlying data it is prohibitively difficult for viewers to create more effective visual representations. In response we present {ReVision}, a system that automatically redesigns visualizations to improve graphical perception. Given a bitmap image of a chart as input, {ReVision} applies computer vision and machine learning techniques to identify the chart type (e.g., pie chart, bar chart, scatterplot, etc.). It then extracts the graphical marks and infers the underlying data. Using a corpus of images drawn from the web, {ReVision} achieves image classification accuracy of 96\% across ten chart categories. It also accurately extracts marks from 79\% of bar charts and 62\% of pie charts, and from these charts it successfully extracts data from 71\% of bar charts and 64\% of pie charts. {ReVision} then applies perceptually-based design principles to populate an interactive gallery of redesigned charts. With this interface, users can view alternative chart designs and retarget content to different visual styles.},
	pages = {393--402},
	booktitle = {Proceedings of the 24th Annual {ACM} Symposium on User Interface Software and Technology},
	publisher = {{ACM}},
	author = {Savva, Manolis and Kong, Nicholas and Chhajta, Arti and Fei-Fei, Li and Agrawala, Maneesh and Heer, Jeffrey},
	urldate = {2017-03-07},
	date = {2011},
	keywords = {chart understanding, computer vision, information extraction, redesign, Visualization},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/WD4IU566/Savva 等. - 2011 - ReVision Automated Classification, Analysis and R.pdf:application/pdf}
}

@article{cleveland_graphical_1984,
	title = {Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods},
	volume = {79},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2288400},
	doi = {10.2307/2288400},
	shorttitle = {Graphical Perception},
	abstract = {The subject of graphical methods for data analysis and for data presentation needs a scientific foundation. In this article we take a few steps in the direction of establishing such a foundation. Our approach is based on graphical perception-the visual decoding of information encoded on graphs-and it includes both theory and experimentation to test the theory. The theory deals with a small but important piece of the whole process of graphical perception. The first part is an identification of a set of elementary perceptual tasks that are carried out when people extract quantitative information from graphs. The second part is an ordering of the tasks on the basis of how accurately people perform them. Elements of the theory are tested by experimentation in which subjects record their judgments of the quantitative information on graphs. The experiments validate these elements but also suggest that the set of elementary tasks should be expanded. The theory provides a guideline for graph construction: Graphs should employ elementary tasks as high in the ordering as possible. This principle is applied to a variety of graphs, including bar charts, divided bar charts, pie charts, and statistical maps with shading. The conclusion is that radical surgery on these popular graphs is needed, and as replacements we offer alternative graphical forms-dot charts, dot charts with grouping, and framed-rectangle charts.},
	pages = {531--554},
	number = {387},
	journaltitle = {Journal of the American Statistical Association},
	author = {Cleveland, William S. and {McGill}, Robert},
	urldate = {2017-03-07},
	date = {1984},
	file = {JSTOR Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/XW55RS7D/Cleveland 和 McGill - 1984 - Graphical Perception Theory, Experimentation, and.pdf:application/pdf}
}

@inproceedings{harper_deconstructing_2014,
	location = {New York, {NY}, {USA}},
	title = {Deconstructing and Restyling D3 Visualizations},
	isbn = {978-1-4503-3069-5},
	url = {http://doi.acm.org/10.1145/2642918.2647411},
	doi = {10.1145/2642918.2647411},
	series = {{UIST} '14},
	abstract = {The D3 {JavaScript} library has become a ubiquitous tool for developing visualizations on the Web. Yet, once a D3 visualization is published online its visual style is difficult to change. We present a pair of tools for deconstructing and restyling existing D3 visualizations. Our deconstruction tool analyzes a D3 visualization to extract the data, the marks and the mappings between them. Our restyling tool lets users modify the visual attributes of the marks as well as the mappings from the data to these attributes. Together our tools allow users to easily modify D3 visualizations without examining the underlying code and we show how they can be used to deconstruct and restyle a variety of D3 visualizations.},
	pages = {253--262},
	booktitle = {Proceedings of the 27th Annual {ACM} Symposium on User Interface Software and Technology},
	publisher = {{ACM}},
	author = {Harper, Jonathan and Agrawala, Maneesh},
	urldate = {2017-03-07},
	date = {2014},
	keywords = {chart understanding, D3, information extraction, redesign, restyling, Visualization},
	file = {ACM Full Text PDF:/Users/wangqianwen/Library/Application Support/Zotero/Profiles/kvj562t5.default/zotero/storage/KPPC44BD/Harper 和 Agrawala - 2014 - Deconstructing and Restyling D3 Visualizations.pdf:application/pdf}
}

@inproceedings{Huang:2007:SUI:1284420.1284427,
 author = {Huang, Weihua and Tan, Chew Lim},
 title = {A System for Understanding Imaged Infographics and Its Applications},
 booktitle = {Proceedings of the 2007 ACM Symposium on Document Engineering},
 series = {DocEng '07},
 year = {2007},
 isbn = {978-1-59593-776-6},
 location = {Winnipeg, Manitoba, Canada},
 pages = {9--18},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1284420.1284427},
 doi = {10.1145/1284420.1284427},
 acmid = {1284427},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {applications, association of text and graphics, document image understanding, infographics},
} 